{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import fitness_energy_utils as utils\n",
    "from src.fitness_energy_utils import NON_FEATURE_COLUMNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17407, 643)\n",
      "['ast-mle-samples-medium.pddl' 'ast-medium-mle-regrowth-samples.pddl']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>src_file</th>\n",
       "      <th>game_name</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>all_variables_defined</th>\n",
       "      <th>all_variables_used</th>\n",
       "      <th>all_preferences_used</th>\n",
       "      <th>setup_objects_used</th>\n",
       "      <th>no_adjacent_once</th>\n",
       "      <th>starts_and_ends_once</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_depth_setup</th>\n",
       "      <th>mean_depth_constraints</th>\n",
       "      <th>mean_depth_terminal</th>\n",
       "      <th>mean_depth_scoring</th>\n",
       "      <th>node_count_setup</th>\n",
       "      <th>node_count_constraints</th>\n",
       "      <th>node_count_terminal</th>\n",
       "      <th>node_count_scoring</th>\n",
       "      <th>real</th>\n",
       "      <th>original_game_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-0</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>14.429293</td>\n",
       "      <td>12.602410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>198</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>game-id-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-1</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.550725</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>24</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>game-id-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-2</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.825397</td>\n",
       "      <td>10.181818</td>\n",
       "      <td>4.941176</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>game-id-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-3</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>11.712919</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>14</td>\n",
       "      <td>209</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>game-id-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-4</td>\n",
       "      <td>few-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>9.047619</td>\n",
       "      <td>6.229885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>game-id-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                     src_file  game_name             domain_name  \\\n",
       "0      0  ast-mle-samples-medium.pddl  game-id-0  medium-objects-room-v1   \n",
       "1      1  ast-mle-samples-medium.pddl  game-id-1  medium-objects-room-v1   \n",
       "2      2  ast-mle-samples-medium.pddl  game-id-2    many-objects-room-v1   \n",
       "3      3  ast-mle-samples-medium.pddl  game-id-3    many-objects-room-v1   \n",
       "4      4  ast-mle-samples-medium.pddl  game-id-4     few-objects-room-v1   \n",
       "\n",
       "   all_variables_defined  all_variables_used  all_preferences_used  \\\n",
       "0                    1.0            0.750000              1.000000   \n",
       "1                    1.0            0.500000              1.000000   \n",
       "2                    1.0            0.750000              1.000000   \n",
       "3                    1.0            0.500000              0.333333   \n",
       "4                    1.0            0.666667              1.000000   \n",
       "\n",
       "   setup_objects_used  no_adjacent_once  starts_and_ends_once  ...  \\\n",
       "0                 0.0               0.5                   0.0  ...   \n",
       "1                 0.0               0.0                   0.0  ...   \n",
       "2                 0.0               1.0                   0.0  ...   \n",
       "3                 1.0               1.0                   0.0  ...   \n",
       "4                 0.0               1.0                   0.0  ...   \n",
       "\n",
       "   mean_depth_setup  mean_depth_constraints  mean_depth_terminal  \\\n",
       "0          5.950000               14.429293            12.602410   \n",
       "1          7.000000               11.550725             2.500000   \n",
       "2          7.825397               10.181818             4.941176   \n",
       "3          3.285714               11.712919             1.571429   \n",
       "4          3.111111                9.047619             6.229885   \n",
       "\n",
       "   mean_depth_scoring  node_count_setup  node_count_constraints  \\\n",
       "0            0.000000                20                     198   \n",
       "1            1.500000                24                      69   \n",
       "2            3.416667                63                      55   \n",
       "3            2.923077                14                     209   \n",
       "4            0.000000                 9                      42   \n",
       "\n",
       "   node_count_terminal  node_count_scoring   real  original_game_name  \n",
       "0                   83                   1  False           game-id-0  \n",
       "1                   10                   4  False           game-id-1  \n",
       "2                   17                  12  False           game-id-2  \n",
       "3                    7                  13  False           game-id-3  \n",
       "4                   87                   1  False           game-id-4  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_df = utils.load_fitness_data('../data/fitness_scores_synthetic.csv')\n",
    "print(fitness_df.shape)\n",
    "print(fitness_df.src_file.unique())\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach in this notebook\n",
    "* Filter the dataset for the top ~100 of a particular provided feature value\n",
    "    *  Perhaps with some warning when there are a lot more than those top-k at the cutoff value?\n",
    "* Fit a fitness model to those\n",
    "* See that the correct feature scored as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17407, 643)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>src_file</th>\n",
       "      <th>game_name</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>all_variables_defined</th>\n",
       "      <th>all_variables_used</th>\n",
       "      <th>all_preferences_used</th>\n",
       "      <th>setup_objects_used</th>\n",
       "      <th>no_adjacent_once</th>\n",
       "      <th>starts_and_ends_once</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_depth_setup</th>\n",
       "      <th>mean_depth_constraints</th>\n",
       "      <th>mean_depth_terminal</th>\n",
       "      <th>mean_depth_scoring</th>\n",
       "      <th>node_count_setup</th>\n",
       "      <th>node_count_constraints</th>\n",
       "      <th>node_count_terminal</th>\n",
       "      <th>node_count_scoring</th>\n",
       "      <th>real</th>\n",
       "      <th>original_game_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-0</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>14.429293</td>\n",
       "      <td>12.602410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>198</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>game-id-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-1</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.550725</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>24</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>game-id-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-2</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.825397</td>\n",
       "      <td>10.181818</td>\n",
       "      <td>4.941176</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>game-id-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-3</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>11.712919</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>14</td>\n",
       "      <td>209</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>game-id-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ast-mle-samples-medium.pddl</td>\n",
       "      <td>game-id-4</td>\n",
       "      <td>few-objects-room-v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>9.047619</td>\n",
       "      <td>6.229885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>game-id-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                     src_file  game_name             domain_name  \\\n",
       "0      0  ast-mle-samples-medium.pddl  game-id-0  medium-objects-room-v1   \n",
       "1      1  ast-mle-samples-medium.pddl  game-id-1  medium-objects-room-v1   \n",
       "2      2  ast-mle-samples-medium.pddl  game-id-2    many-objects-room-v1   \n",
       "3      3  ast-mle-samples-medium.pddl  game-id-3    many-objects-room-v1   \n",
       "4      4  ast-mle-samples-medium.pddl  game-id-4     few-objects-room-v1   \n",
       "\n",
       "   all_variables_defined  all_variables_used  all_preferences_used  \\\n",
       "0                    1.0            0.750000              1.000000   \n",
       "1                    1.0            0.500000              1.000000   \n",
       "2                    1.0            0.750000              1.000000   \n",
       "3                    1.0            0.500000              0.333333   \n",
       "4                    1.0            0.666667              1.000000   \n",
       "\n",
       "   setup_objects_used  no_adjacent_once  starts_and_ends_once  ...  \\\n",
       "0                 0.0               0.5                   0.0  ...   \n",
       "1                 0.0               0.0                   0.0  ...   \n",
       "2                 0.0               1.0                   0.0  ...   \n",
       "3                 1.0               1.0                   0.0  ...   \n",
       "4                 0.0               1.0                   0.0  ...   \n",
       "\n",
       "   mean_depth_setup  mean_depth_constraints  mean_depth_terminal  \\\n",
       "0          5.950000               14.429293            12.602410   \n",
       "1          7.000000               11.550725             2.500000   \n",
       "2          7.825397               10.181818             4.941176   \n",
       "3          3.285714               11.712919             1.571429   \n",
       "4          3.111111                9.047619             6.229885   \n",
       "\n",
       "   mean_depth_scoring  node_count_setup  node_count_constraints  \\\n",
       "0            0.000000                20                     198   \n",
       "1            1.500000                24                      69   \n",
       "2            3.416667                63                      55   \n",
       "3            2.923077                14                     209   \n",
       "4            0.000000                 9                      42   \n",
       "\n",
       "   node_count_terminal  node_count_scoring  real  original_game_name  \n",
       "0                   83                   1     1           game-id-0  \n",
       "1                   10                   4     1           game-id-1  \n",
       "2                   17                  12     1           game-id-2  \n",
       "3                    7                  13     1           game-id-3  \n",
       "4                   87                   1     1           game-id-4  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_syntethic_df(df: pd.DataFrame, \n",
    "    synthetic_data_src_files: typing.Sequence[str] = ('ast-mle-samples-medium.pddl', 'ast-medium-mle-regrowth-samples.pddl'),\n",
    "    original_game_ids: typing.Optional[typing.Sequence[str]] = None,\n",
    "    \n",
    "    ) -> pd.DataFrame:\n",
    "    syntethic_df = fitness_df[fitness_df.src_file.isin(synthetic_data_src_files)].reset_index(drop=True)\n",
    "    # if 'ast-mle-samples.pddl' in synthetic_data_src_files:\n",
    "    #     syntethic_df.loc[syntethic_df.src_file == 'ast-mle-samples.pddl', 'original_game_name'] = syntethic_df.loc[syntethic_df.src_file == 'ast-mle-samples.pddl', 'game_name']\n",
    "    if original_game_ids is not None:\n",
    "        syntethic_df = syntethic_df[syntethic_df.original_game_name.isin(original_game_ids)].reset_index(drop=True)\n",
    "\n",
    "    syntethic_df.loc[syntethic_df.src_file == synthetic_data_src_files[0], 'real'] = 1\n",
    "        \n",
    "    return syntethic_df\n",
    "\n",
    "syntethic_fitness_df = base_syntethic_df(fitness_df)\n",
    "print(syntethic_fitness_df.shape)\n",
    "syntethic_fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game-id-0       False\n",
       "game-id-687     False\n",
       "game-id-674     False\n",
       "game-id-675     False\n",
       "game-id-676     False\n",
       "                ...  \n",
       "game-id-347     False\n",
       "game-id-348     False\n",
       "game-id-349     False\n",
       "game-id-1023    False\n",
       "game-id-760      True\n",
       "Name: original_game_name, Length: 1024, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntethic_fitness_df.original_game_name.value_counts() != 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_objects_used: 122\n",
      "variable_not_repeated: 145\n",
      "correct_predicate_arity: 146\n",
      "no_variable_twice_in_predicate: 143\n",
      "pred_arg_types_agent_holds_balls: 110\n",
      "pred_arg_types_agent_holds_large_objects: 104\n",
      "pred_arg_types_in_motion_agent: 102\n",
      "pred_arg_types_in_motion_room_features: 150\n",
      "pred_arg_types_on_balls_balls: 100\n",
      "max_depth_setup: 121\n",
      "max_depth_constraints: 102\n",
      "max_depth_terminal: 120\n",
      "max_depth_scoring: 138\n",
      "mean_depth_setup: 100\n",
      "mean_depth_constraints: 100\n",
      "mean_depth_terminal: 100\n",
      "mean_depth_scoring: 100\n",
      "node_count_setup: 101\n",
      "node_count_constraints: 100\n",
      "node_count_terminal: 100\n",
      "node_count_scoring: 101\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "max_ratio = 1.5\n",
    "\n",
    "synthetic_real_df = syntethic_fitness_df[syntethic_fitness_df.real == 1]\n",
    "\n",
    "for c in syntethic_fitness_df.columns:\n",
    "    if c not in NON_FEATURE_COLUMNS:\n",
    "        top_k_df = synthetic_real_df.nlargest(k, c)\n",
    "        min_value = top_k_df[c].min()\n",
    "        top_k_value_count = (synthetic_real_df[c] >= min_value).sum()\n",
    "\n",
    "        if top_k_value_count <= k * max_ratio:\n",
    "            print(f'{c}: {top_k_value_count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic experiment approach\n",
    "* Pick one feature value that is the 'target' feature for this experiment\n",
    "* For each set of games generated from the same 'source' synthetic game:\n",
    "    * Find the game in that set that has the highest value on that feature\n",
    "    * Define that game to the be positive game for the recovery experiment with this feature; treat the remaining games as the negatives. \n",
    "* At this point, we have a single designated positive game from each set. \n",
    "* Fit the fitness model with these labels.\n",
    "* Check whether or not the highest coefficient belongs to the feature picked initially.\n",
    "* Repeat for other features, and potentially for feature combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_IDS_TO_SKIP = set(['game-id-760'])\n",
    "\n",
    "def cross_validate(train: pd.DataFrame, feature_columns: typing.List[str],\n",
    "    param_grid: typing.Union[typing.List[typing.Dict[str, typing.Any]], typing.Dict[str, typing.Any]],\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None, \n",
    "    cv_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    n_folds: int = 5, verbose: int = 0):\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    if train_kwargs is None:\n",
    "        train_kwargs = {}\n",
    "\n",
    "    if cv_kwargs is None:\n",
    "        cv_kwargs = {}\n",
    "\n",
    "    if 'n_jobs' not in cv_kwargs: \n",
    "        cv_kwargs['n_jobs'] = -1\n",
    "    if 'verbose' not in cv_kwargs:\n",
    "        cv_kwargs['verbose'] = verbose\n",
    "\n",
    "    train_tensor = utils.df_to_tensor(train, feature_columns)\n",
    "    pipeline = Pipeline(steps=[('scaler', utils.CustomSklearnScaler()), ('fitness', utils.SklearnFitnessWrapper(model_kwargs=model_kwargs, train_kwargs=train_kwargs))])\n",
    "\n",
    "    if isinstance(param_grid, list):\n",
    "        for param_grid_dict in param_grid:\n",
    "            param_grid_dict['fitness__n_features'] = [len(feature_columns)]\n",
    "    else:\n",
    "        param_grid['fitness__n_features'] = [len(feature_columns)]        \n",
    "\n",
    "    random_seed = train_kwargs['random_seed'] if 'random_seed' in train_kwargs else None\n",
    "\n",
    "    cv = GridSearchCV(pipeline, param_grid, scoring=scoring_function, \n",
    "        cv=KFold(n_folds, shuffle=True, random_state=random_seed), \n",
    "        **cv_kwargs)\n",
    "    return cv.fit(train_tensor, None)\n",
    "\n",
    "\n",
    "def single_feature_top_k_parameter_recovery_experiment(df: pd.DataFrame, target_feature: str, k: int,\n",
    "    param_grid: typing.Union[typing.List[typing.Dict[str, typing.Any]], typing.Dict[str, typing.Any]], \n",
    "    feature_columns: typing.Optional[typing.List[str]] = None, \n",
    "    random_seed: int = utils.DEFAULT_RANDOM_SEED,\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    cv_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    n_folds: int = 5, verbose: int = 0,\n",
    "    top_k_warning_threshold: float = 1.5,\n",
    "    game_ids_to_skip: typing.Set[str] = GAME_IDS_TO_SKIP,\n",
    "    ):\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    if train_kwargs is None:\n",
    "        train_kwargs = {}\n",
    "\n",
    "    syntethic_fitness_df = base_syntethic_df(df)\n",
    "    syntethic_reals_df = syntethic_fitness_df[syntethic_fitness_df.real == 1]\n",
    "\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "    elif target_feature not in feature_columns:\n",
    "        raise ValueError(f'Target feature {target_feature} not in feature_columns')\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    top_k_df = syntethic_reals_df.nlargest(k, target_feature)\n",
    "    min_value = top_k_df[target_feature].min()\n",
    "    top_k_value_count = (syntethic_reals_df[target_feature] >= min_value).sum()\n",
    "\n",
    "    if top_k_value_count > k * top_k_warning_threshold:\n",
    "        raise ValueError(f'WARNING: Top {k} value count {top_k_value_count} is greater than threshold {k * top_k_warning_threshold}')\n",
    "\n",
    "    top_k_games = set(top_k_df.game_name)\n",
    "    top_k_games.difference_update(game_ids_to_skip)\n",
    "    filtered_synthetic_df = syntethic_fitness_df[syntethic_fitness_df.original_game_name.isin(top_k_games)].reset_index(drop=True)\n",
    "\n",
    "    train_df, test_df = utils.train_test_split_by_game_name(filtered_synthetic_df, random_seed=random_seed)\n",
    "    cv = cross_validate(train_df, feature_columns, param_grid, \n",
    "        scoring_function=scoring_function,\n",
    "        train_kwargs={'random_seed': random_seed, **train_kwargs}, \n",
    "        model_kwargs=model_kwargs, cv_kwargs=cv_kwargs, n_folds=n_folds, verbose=verbose)\n",
    "    best_model = cv.best_estimator_.named_steps['fitness'].model  # type: ignore\n",
    "    weights = best_model.fc1.weight.detach().numpy().reshape(-1)\n",
    "\n",
    "    target_feature_index = feature_columns.index(target_feature)\n",
    "    target_feature_is_max_weight = weights.argmax() == target_feature_index\n",
    "    target_feature_weight_diff = weights[target_feature_index] - weights[np.arange(len(weights)) != target_feature_index].max()\n",
    "\n",
    "    weight_argsort = np.argsort(weights)\n",
    "    ranks = np.empty_like(weight_argsort)\n",
    "    ranks[weight_argsort] = np.arange(len(weights))\n",
    "    target_feature_rank = ranks[target_feature_index]\n",
    "\n",
    "    return {\n",
    "        'target_feature': target_feature,\n",
    "        'random_seed': random_seed,\n",
    "        'is_max_weight': target_feature_is_max_weight,\n",
    "        'weight_diff': target_feature_weight_diff,\n",
    "        'rank': target_feature_rank,\n",
    "        'best_params': cv.best_params_,\n",
    "        'best_score': cv.best_score_,\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e2a899e462459ebde1eb33b9030916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_param_grid = [\n",
    "    {\n",
    "        'fitness__loss_function': [utils.fitness_hinge_loss],\n",
    "        'fitness__weight_decay': [0.0, 0.125, 0.25, 0.5, 1],  \n",
    "        'fitness__margin': [1, 2, 4],\n",
    "        'fitness__lr': [1e-2, 3e-3, 1e-3, 3e-4],\n",
    "        'fitness__k': [4, 8, 16],\n",
    "        'fitness__batch_size': [1, 4, 8, 16],\n",
    "    },\n",
    "    # TODO: add other loss functions\n",
    "]\n",
    "\n",
    "K = 100\n",
    "RANDOM_SEED = 33\n",
    "results_by_feature = dict()\n",
    "relevant_feature_columns = [\n",
    "    'setup_objects_used', 'variable_not_repeated', \n",
    "    'correct_predicate_arity', 'no_variable_twice_in_predicate', \n",
    "    'pred_arg_types_agent_holds_balls', \n",
    "    'pred_arg_types_agent_holds_large_objects', \n",
    "    'pred_arg_types_in_motion_agent',\n",
    "    'pred_arg_types_in_motion_room_features', \n",
    "    'pred_arg_types_on_balls_balls']\n",
    "pbar = tqdm.tqdm(total=len(relevant_feature_columns))\n",
    "\n",
    "for target_feature in relevant_feature_columns:\n",
    "    pbar.set_description(f'Feature {target_feature}')\n",
    "    results_by_feature[target_feature] = single_feature_top_k_parameter_recovery_experiment(\n",
    "        syntethic_fitness_df, target_feature, K, test_param_grid, random_seed=RANDOM_SEED)\n",
    "    pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "index = 0\n",
    "\n",
    "for target_feature in results_by_feature:\n",
    "    results = results_by_feature[target_feature]\n",
    "    weight_diffs = [r['weight_diff'] for r in results]\n",
    "    ax = axes[index // 5][index % 5]\n",
    "    ax.hist(weight_diffs, bins=5)\n",
    "    ax.set_title(f'{target_feature} weight diffs\\nP(max) = {np.mean([r[\"is_max_weight\"] for r in results]):.2f}')\n",
    "    ax.set_xlabel(f'Weight diff (target - max(others))')\n",
    "    ax.set_ylabel('Count')\n",
    "    index += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_two_feature_parameter_recovery_experiment(df: pd.DataFrame, \n",
    "    positive_target_feature: str, negative_target_feature: str,\n",
    "    param_grid: typing.Dict[str, typing.Any], target_feature_epsilon: float = 0,\n",
    "    feature_columns: typing.Optional[typing.List[str]] = None, \n",
    "    random_seed: int = utils.DEFAULT_RANDOM_SEED,\n",
    "    scoring_function: typing.Callable = utils.evaluate_fitness,\n",
    "    model_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "    train_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None,):\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    if train_kwargs is None:\n",
    "        train_kwargs = {}\n",
    "    \n",
    "    syntethic_fitness_df = base_syntethic_df(df)\n",
    "\n",
    "    if feature_columns is None:\n",
    "        feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "    elif positive_target_feature not in feature_columns:\n",
    "        raise ValueError(f'Positive target feature {positive_target_feature} not in feature_columns')\n",
    "    elif negative_target_feature not in feature_columns:\n",
    "        raise ValueError(f'Negative target feature {negative_target_feature} not in feature_columns')\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    unique_games = list(syntethic_fitness_df.original_game_name.unique())\n",
    "\n",
    "    game_idxmaxes = []\n",
    "    game_values = []\n",
    "    for original_game in unique_games:\n",
    "        pos_game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][positive_target_feature]\n",
    "        neg_game_col = syntethic_fitness_df[syntethic_fitness_df.original_game_name == original_game][negative_target_feature]\n",
    "        diff = pos_game_col - neg_game_col\n",
    "        idx = rng.choice(np.argwhere(diff.values == diff.values.max()).reshape(-1))\n",
    "        game_idxmaxes.append(pos_game_col.index[idx])\n",
    "        game_values.append(diff.values.max())\n",
    "\n",
    "    syntethic_fitness_df.real = 0\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, 'real'] = 1\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, positive_target_feature] += target_feature_epsilon\n",
    "    syntethic_fitness_df.loc[game_idxmaxes, negative_target_feature] -= target_feature_epsilon\n",
    "\n",
    "    feature_combination_group_by = syntethic_fitness_df.groupby('original_game_name').apply(lambda df: df[positive_target_feature] - df[negative_target_feature]).groupby('original_game_name').max()\n",
    "    \n",
    "    for i, original_game in enumerate(unique_games):\n",
    "        assert(feature_combination_group_by[original_game] == (syntethic_fitness_df.loc[game_idxmaxes[i], positive_target_feature] - syntethic_fitness_df.loc[game_idxmaxes[i], negative_target_feature]))  # type: ignore\n",
    "\n",
    "    train_df, test_df = utils.train_test_split_by_game_name(syntethic_fitness_df, random_seed=random_seed)\n",
    "    cv = cross_validate(train_df, feature_columns, param_grid, scoring_function=scoring_function,\n",
    "        train_kwargs={'random_seed': random_seed, **train_kwargs}, model_kwargs=model_kwargs)\n",
    "    best_model = cv.best_estimator_.named_steps['fitness'].model  # type: ignore\n",
    "    weights = best_model.fc1.weight.detach().numpy().reshape(-1)\n",
    "\n",
    "    pos_target_feature_index = feature_columns.index(positive_target_feature)\n",
    "    pos_target_feature_is_max_weight = weights.argmax() == pos_target_feature_index\n",
    "    pos_target_feature_is_min_weight = weights.argmin() == pos_target_feature_index\n",
    "    pos_target_feature_weight_diff = weights[pos_target_feature_index] - weights[np.arange(len(weights)) != pos_target_feature_index].max()\n",
    "\n",
    "    neg_target_feature_index = feature_columns.index(negative_target_feature)\n",
    "    neg_target_feature_is_max_weight = weights.argmax() == neg_target_feature_index\n",
    "    neg_target_feature_is_min_weight = weights.argmin() == neg_target_feature_index\n",
    "    neg_target_feature_weight_diff = weights[neg_target_feature_index] - weights[np.arange(len(weights)) != neg_target_feature_index].min()\n",
    "\n",
    "    return {\n",
    "        'pos_target_feature': positive_target_feature,\n",
    "        'neg_target_feature': negative_target_feature,\n",
    "        'random_seed': random_seed,\n",
    "        'pos_is_max_weight': pos_target_feature_is_max_weight,\n",
    "        'pos_is_min_weight': pos_target_feature_is_min_weight,\n",
    "        'pos_weight_diff': pos_target_feature_weight_diff,\n",
    "        'neg_is_max_weight': neg_target_feature_is_max_weight,\n",
    "        'neg_is_min_weight': neg_target_feature_is_min_weight,\n",
    "        'neg_weight_diff': neg_target_feature_weight_diff,\n",
    "        'best_params': cv.best_params_,\n",
    "        'best_score': cv.best_score_,\n",
    "        'target_feature_epsilon': target_feature_epsilon,\n",
    "    }\n",
    "    \n",
    "\n",
    "DEFAULT_LEGEND_KWARGS = dict(loc='upper left', bbox_to_anchor=(1.05, 1.425))\n",
    "DEFAULT_SUBPLOT_ADJUST_PARAMS = dict(hspace=0.35, wspace=0.3)\n",
    "    \n",
    "def plot_two_feature_parameter_recovery_experiment_results(\n",
    "    results_by_feature: typing.Dict[typing.Tuple[str, str], typing.List[typing.Dict[str, typing.Any]]], \n",
    "    feature_columns: typing.List[str], flip_features: bool = False,\n",
    "    layout: typing.Tuple[int, int] = (2, 5), figsize: typing.Tuple[int, int] = (20, 10),\n",
    "    title: typing.Optional[str] = None, colormap: str = 'tab10',\n",
    "    legend_kwargs: typing.Dict[str, typing.Any] = DEFAULT_LEGEND_KWARGS,\n",
    "    subplot_adjust_params: typing.Dict[str, typing.Any] = DEFAULT_SUBPLOT_ADJUST_PARAMS,\n",
    "    ):\n",
    "\n",
    "    cmap = plt.get_cmap(colormap)  # type: ignore\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "    index = 0\n",
    "\n",
    "    for target_feature in feature_columns:\n",
    "        positive_keys = [k for k in results_by_feature.keys() if k[0] == target_feature]\n",
    "        negative_keys = [k for k in results_by_feature.keys() if k[1] == target_feature]\n",
    "\n",
    "        positive_results = [results_by_feature[k] for k in positive_keys]\n",
    "        negative_results = [results_by_feature[k] for k in negative_keys]\n",
    "\n",
    "        positive_weight_diffs = [r['pos_weight_diff'] for r in itertools.chain(*positive_results)]\n",
    "        negative_weight_diffs = [r['neg_weight_diff'] for r in itertools.chain(*negative_results)]\n",
    "\n",
    "        if flip_features:\n",
    "            max_key = 'neg_is_max_weight'\n",
    "            min_key = 'pos_is_min_weight'\n",
    "        else:\n",
    "            max_key = 'pos_is_max_weight'\n",
    "            min_key = 'neg_is_min_weight'\n",
    "\n",
    "        feature_is_max_weight = [r[max_key] for r in itertools.chain(*positive_results)]\n",
    "        feature_is_min_weight = [r[min_key] for r in itertools.chain(*negative_results)]\n",
    "\n",
    "        ax = axes[index // 5][index % 5]\n",
    "        positive_color, negative_color = cmap(0), cmap(1)\n",
    "        if flip_features:\n",
    "            positive_color, negative_color = negative_color, positive_color\n",
    "\n",
    "        ax.hist(positive_weight_diffs, color=positive_color, label='Positive feature\\nregression weight')\n",
    "        ax.hist(negative_weight_diffs, color=negative_color, label='Negative feature\\nregression weight')\n",
    "\n",
    "        max_mean, min_mean = np.mean(feature_is_max_weight), np.mean(feature_is_min_weight)\n",
    "        ax.set_title(f'{target_feature} weight diffs\\nP(min) = {min_mean:.2f} | P(max) = {max_mean:.2f}')\n",
    "        ax.set_xlabel(f'Weight diff (target - max/min(others))')\n",
    "        ax.set_ylabel('Count')\n",
    "        index += 1\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    plt.legend(**legend_kwargs)\n",
    "    plt.subplots_adjust(**subplot_adjust_params)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,]   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "\n",
    "two_feature_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(two_feature_results_by_feature, all_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,],\n",
    "    'fitness__margin': [1, 2, 4],   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_hinge_loss}\n",
    "\n",
    "two_feature_hinge_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_hinge_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_hinge_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,]   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_log_loss}\n",
    "\n",
    "two_feature_log_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_log_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_log_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_grid = {\n",
    "    'fitness__n_outputs': [1], \n",
    "    'fitness__weight_decay': [0.0, 0.01, 0.05, 0.1], \n",
    "    'fitness__hidden_size': [None,],\n",
    "    'fitness__margin': [1, 2, 4],   \n",
    "}\n",
    "\n",
    "N_SEEDS = 10\n",
    "START_SEED = utils.DEFAULT_RANDOM_SEED\n",
    "\n",
    "all_feature_columns = [c for c in syntethic_fitness_df.columns if c not in NON_FEATURE_COLUMNS]\n",
    "model_kwargs = {'output_activation': nn.Identity()}\n",
    "train_kwargs = {'loss_function': utils.fitness_square_square_loss}\n",
    "\n",
    "two_feature_square_square_loss_results_by_feature = defaultdict(list)\n",
    "pbar = tqdm.tqdm(list(itertools.permutations(all_feature_columns, 2)))\n",
    "for positive_target_feature, negative_target_feature in pbar:\n",
    "    pbar.set_description(f'Processing {positive_target_feature} - {negative_target_feature}')\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        two_feature_square_square_loss_results_by_feature[(positive_target_feature, negative_target_feature)].append(single_two_feature_parameter_recovery_experiment(\n",
    "            syntethic_fitness_df, positive_target_feature, negative_target_feature, test_param_grid, random_seed=seed, \n",
    "            scoring_function=utils.evaluate_fitness_flipped_sign, model_kwargs=model_kwargs, train_kwargs=train_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_feature_parameter_recovery_experiment_results(\n",
    "    two_feature_square_square_loss_results_by_feature, all_feature_columns, flip_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging thoughts about these new losses\n",
    "* Plot my loss implementations to make sure they behave as expected\n",
    "* Verify my scoring function works and the model returned is actually the best one\n",
    "* Try the square-square loss as well\n",
    "* Cross validate over other margins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('game-gen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d207b42274502bc006609ff0f580407f35ab20e7889cda7ddd92e73aeb06c569"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
