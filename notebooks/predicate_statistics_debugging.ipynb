{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import difflib\n",
    "import duckdb\n",
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "from IPython.display import display, Markdown, HTML  # type: ignore\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import tatsu, tatsu.ast\n",
    "import tqdm.notebook as tqdmn\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "sys.path.append(os.path.abspath('../reward-machine'))\n",
    "\n",
    "import compile_predicate_statistics\n",
    "import compile_predicate_statistics_split_args\n",
    "from compile_predicate_statistics_split_args import *\n",
    "from config import SPECIFIC_NAMED_OBJECTS_BY_ROOM\n",
    "\n",
    "import ast_printer\n",
    "import ast_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625506, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 15:20:11 - compile_predicate_statistics_split_args - INFO     - Loaded data with shape (2703800, 8) from /Users/guydavidson/projects/game-generation-modeling/reward-machine/caches/predicate_statistics_028b3733.pkl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering out same_type, data has shape (625506, 8)\n"
     ]
    }
   ],
   "source": [
    "cache_dir = compile_predicate_statistics.get_project_dir() + '/reward-machine/caches'\n",
    "\n",
    "# regular_df = pd.read_pickle(os.path.join(cache_dir, 'predicate_statistics.pkl'))\n",
    "split_args_df = pd.read_pickle(os.path.join(cache_dir, 'predicate_statistics_028b3733.pkl.gz'))\n",
    "split_args_df = split_args_df[split_args_df['predicate'] != 'same_type']\n",
    "print(split_args_df.shape)\n",
    "# split_args_df = pd.read_pickle(os.path.join(cache_dir, 'predicate_statistics_4d5dd602.pkl.gz'))\n",
    "\n",
    "# stats = compile_predicate_statistics.CommonSensePredicateStatistics(cache_dir)\n",
    "split_args_stats = compile_predicate_statistics_split_args.CommonSensePredicateStatisticsSplitArgs(\n",
    "    # cache_dir, compile_predicate_statistics_split_args.CURRENT_TEST_TRACE_NAMES, overwrite=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625506, 8)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_args_df_no_same_type = split_args_df[split_args_df['predicate'] != 'same_type'].drop(columns=['string_intervals'])\n",
    "split_args_df_no_same_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_args_df_no_same_type.to_pickle(os.path.join(cache_dir, 'predicate_statistics_028b3733.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35172"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_args_stats.trace_lengths_and_domains_df.select(pl.col('trace_length').max()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(10000, dtype=np.uint8)\n",
    "a[100:1000] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros(10, dtype=np.uint8)\n",
    "t[1:4] = 1\n",
    "b = t.tobytes()\n",
    "d = {b[0]: '0', b[1]: '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0111000000'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(map(lambda x: d[x], b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x01'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = bytes([0, 1])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35172\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = split_args_stats.trace_lengths_and_domains_df.select(pl.col('trace_length').max()).item()\n",
    "print(MAX_LENGTH)\n",
    "b = bytes([0, 1])\n",
    "BYTE_MAPPING = {b: str(i) for i, b in enumerate(b)}\n",
    "\n",
    "\n",
    "\n",
    "def intervals_to_string(intervals, max_length: int = MAX_LENGTH):\n",
    "    value = np.zeros(max_length, dtype=np.uint8)\n",
    "    for interval in intervals:\n",
    "        value[interval[0]:interval[1]] = 1\n",
    "\n",
    "    return ''.join(map(lambda b: BYTE_MAPPING[b], value.tobytes()))\n",
    "    # return np.array2string(value, separator='', threshold=max_length + 10)[1:-1].replace('\\n ', '')\n",
    "\n",
    "\n",
    "string_intervals = split_args_df.intervals.apply(intervals_to_string)\n",
    "\n",
    "# small_split_args_df = small_split_args_df.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicate</th>\n",
       "      <th>arg_1_id</th>\n",
       "      <th>arg_1_type</th>\n",
       "      <th>arg_2_id</th>\n",
       "      <th>arg_2_type</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>intervals</th>\n",
       "      <th>string_intervals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>Shelf|-02.97|+01.53|-01.72</td>\n",
       "      <td>shelf</td>\n",
       "      <td>Shelf|-02.97|+01.53|-02.47</td>\n",
       "      <td>shelf</td>\n",
       "      <td>1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...</td>\n",
       "      <td>medium</td>\n",
       "      <td>[[0, 1612]]</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>Shelf|-02.97|+01.53|-02.47</td>\n",
       "      <td>shelf</td>\n",
       "      <td>Shelf|-02.97|+01.53|-01.72</td>\n",
       "      <td>shelf</td>\n",
       "      <td>1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...</td>\n",
       "      <td>medium</td>\n",
       "      <td>[[0, 1612]]</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>Shelf|-02.97|+01.53|-01.72</td>\n",
       "      <td>shelf</td>\n",
       "      <td>west_wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...</td>\n",
       "      <td>medium</td>\n",
       "      <td>[[0, 1612]]</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>west_wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>Shelf|-02.97|+01.53|-01.72</td>\n",
       "      <td>shelf</td>\n",
       "      <td>1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...</td>\n",
       "      <td>medium</td>\n",
       "      <td>[[0, 1612]]</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>Shelf|+00.62|+01.01|-02.82</td>\n",
       "      <td>shelf</td>\n",
       "      <td>BridgeBlock|+01.03|+01.11|-02.88</td>\n",
       "      <td>bridge_block</td>\n",
       "      <td>1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...</td>\n",
       "      <td>medium</td>\n",
       "      <td>[[0, 1612]]</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predicate                    arg_1_id arg_1_type  \\\n",
       "0  adjacent  Shelf|-02.97|+01.53|-01.72      shelf   \n",
       "1  adjacent  Shelf|-02.97|+01.53|-02.47      shelf   \n",
       "2  adjacent  Shelf|-02.97|+01.53|-01.72      shelf   \n",
       "3  adjacent                   west_wall       wall   \n",
       "4  adjacent  Shelf|+00.62|+01.01|-02.82      shelf   \n",
       "\n",
       "                           arg_2_id    arg_2_type  \\\n",
       "0        Shelf|-02.97|+01.53|-02.47         shelf   \n",
       "1        Shelf|-02.97|+01.53|-01.72         shelf   \n",
       "2                         west_wall          wall   \n",
       "3        Shelf|-02.97|+01.53|-01.72         shelf   \n",
       "4  BridgeBlock|+01.03|+01.11|-02.88  bridge_block   \n",
       "\n",
       "                                            trace_id  domain    intervals  \\\n",
       "0  1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...  medium  [[0, 1612]]   \n",
       "1  1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...  medium  [[0, 1612]]   \n",
       "2  1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...  medium  [[0, 1612]]   \n",
       "3  1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...  medium  [[0, 1612]]   \n",
       "4  1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rereco...  medium  [[0, 1612]]   \n",
       "\n",
       "                                    string_intervals  \n",
       "0  1111111111111111111111111111111111111111111111...  \n",
       "1  1111111111111111111111111111111111111111111111...  \n",
       "2  1111111111111111111111111111111111111111111111...  \n",
       "3  1111111111111111111111111111111111111111111111...  \n",
       "4  1111111111111111111111111111111111111111111111...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_args_df = split_args_df.assign(string_intervals=string_intervals)\n",
    "split_args_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bac00c0ae94a2b9408428d333b29ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────┬─────────┬─────────┬─────────┬───────┐\n",
      "│   column_name    │ column_type │  null   │   key   │ default │ extra │\n",
      "│     varchar      │   varchar   │ varchar │ varchar │ varchar │ int32 │\n",
      "├──────────────────┼─────────────┼─────────┼─────────┼─────────┼───────┤\n",
      "│ predicate        │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_1_id         │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_1_type       │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_2_id         │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_2_type       │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ trace_id         │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ domain           │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ intervals        │ INTEGER[][] │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ string_intervals │ BIT         │ YES     │ NULL    │ NULL    │  NULL │\n",
      "└──────────────────┴─────────────┴─────────┴─────────┴─────────┴───────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duckdb.sql('DROP TABLE data')\n",
    "duckdb.sql('CREATE TABLE data AS SELECT * FROM split_args_df')\n",
    "duckdb.sql('ALTER TABLE data ALTER string_intervals TYPE BITSTRING')\n",
    "duckdb.sql('DESCRIBE data').show()\n",
    "\n",
    "# duckdb.sql(\"CREATE TYPE predicate AS ENUM (SELECT predicate FROM split_args_df);\")\n",
    "# duckdb.sql(\"CREATE TYPE domain AS ENUM (SELECT domain FROM split_args_df);\")\n",
    "# duckdb.sql(\"CREATE TYPE trace_id AS ENUM (SELECT trace_id FROM split_args_df);\")\n",
    "# all_types = tuple([t for t in set(split_args_df.arg_1_type.unique()) | set(split_args_df.arg_2_type.unique()) if isinstance(t, str) ])\n",
    "# duckdb.sql(f\"CREATE TYPE arg_type AS ENUM {all_types};\")\n",
    "# all_ids = tuple([t for t in set(split_args_df.arg_1_id.unique()) | set(split_args_df.arg_2_id.unique()) if isinstance(t, str)])\n",
    "# duckdb.sql(f\"CREATE TYPE arg_id AS ENUM {all_ids};\")\n",
    "\n",
    "# duckdb.sql('ALTER TABLE data ALTER predicate TYPE predicate')\n",
    "# duckdb.sql('ALTER TABLE data ALTER domain TYPE domain')\n",
    "# duckdb.sql('ALTER TABLE data ALTER trace_id TYPE trace_id')\n",
    "# duckdb.sql('ALTER TABLE data ALTER arg_1_type TYPE arg_type')\n",
    "# duckdb.sql('ALTER TABLE data ALTER arg_2_type TYPE arg_type')\n",
    "# duckdb.sql('ALTER TABLE data ALTER arg_1_id TYPE arg_id')\n",
    "# duckdb.sql('ALTER TABLE data ALTER arg_2_id TYPE arg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────────────────────────┬──────────────┬──────────┐\n",
      "│                      trace_id                      │ trace_length │  domain  │\n",
      "│                      trace_id                      │    int64     │ \"domain\" │\n",
      "├────────────────────────────────────────────────────┼──────────────┼──────────┤\n",
      "│ 1El1CmicSoKZKTLe8NpP-gameplay-attempt-1-rerecorded │         1612 │ medium   │\n",
      "│ 1El1CmicSoKZKTLe8NpP-gameplay-attempt-2-rerecorded │           56 │ medium   │\n",
      "│ 1El1CmicSoKZKTLe8NpP-preCreateGame-rerecorded      │         1250 │ medium   │\n",
      "│ 1HOTuIZpRqk2u1nZI1v1-gameplay-attempt-1-rerecorded │          921 │ many     │\n",
      "│ 1HOTuIZpRqk2u1nZI1v1-preCreateGame-rerecorded      │          550 │ many     │\n",
      "│ 1aTng0m9240WEAU975WE-createGame-rerecorded         │          648 │ few      │\n",
      "│ 1aTng0m9240WEAU975WE-gameplay-attempt-1-rerecorded │          984 │ few      │\n",
      "│ 1aTng0m9240WEAU975WE-gameplay-attempt-2-rerecorded │         1387 │ few      │\n",
      "│ 1aTng0m9240WEAU975WE-preCreateGame-rerecorded      │          685 │ few      │\n",
      "│ 39PytL3fAMFkYXNoB5l6-createGame-rerecorded         │         5629 │ many     │\n",
      "│                     ·                              │           ·  │  ·       │\n",
      "│                     ·                              │           ·  │  ·       │\n",
      "│                     ·                              │           ·  │  ·       │\n",
      "│ xKsIJRkAQ3ELL4W0K0wq-gameplay-attempt-1-rerecorded │         1039 │ few      │\n",
      "│ xMUrxzK3fXjgitdzPKsm-freePlay-rerecorded           │          143 │ many     │\n",
      "│ xMUrxzK3fXjgitdzPKsm-gameplay-attempt-1-rerecorded │         7159 │ many     │\n",
      "│ xMUrxzK3fXjgitdzPKsm-preCreateGame-rerecorded      │         5310 │ many     │\n",
      "│ yWwOhJSjWiuzNkkHzhft-createGame-rerecorded         │         4639 │ few      │\n",
      "│ yWwOhJSjWiuzNkkHzhft-gameplay-attempt-2-rerecorded │          510 │ few      │\n",
      "│ yWwOhJSjWiuzNkkHzhft-gameplay-attempt-5-rerecorded │         4663 │ few      │\n",
      "│ zhq2iVuBVQxs15gj7Blw-createGame-rerecorded         │          772 │ many     │\n",
      "│ zhq2iVuBVQxs15gj7Blw-gameplay-attempt-1-rerecorded │          467 │ many     │\n",
      "│ zhq2iVuBVQxs15gj7Blw-preCreateGame-rerecorded      │         2541 │ many     │\n",
      "├────────────────────────────────────────────────────┴──────────────┴──────────┤\n",
      "│ 382 rows (20 shown)                                                3 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tld_df = split_args_stats.trace_lengths_and_domains_df\n",
    "duckdb.sql('DROP TABLE trace_lengths_domains')\n",
    "duckdb.sql('CREATE TABLE trace_lengths_domains AS SELECT * FROM tld_df')\n",
    "duckdb.sql('ALTER TABLE trace_lengths_domains ALTER domain TYPE domain')\n",
    "duckdb.sql('ALTER TABLE trace_lengths_domains ALTER trace_id TYPE trace_id')\n",
    "duckdb.sql('SELECT * FROM trace_lengths_domains').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────┐\n",
       "│ arg_1_type │\n",
       "│  arg_type  │\n",
       "├────────────┤\n",
       "│   0 rows   │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT arg_1_type FROM data WHERE arg_1_type='ball'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────────────────────────┐\n",
       "│               ?b               │\n",
       "│             arg_id             │\n",
       "├────────────────────────────────┤\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│ Dodgeball|-02.60|+00.13|-02.18 │\n",
       "│               ·                │\n",
       "│               ·                │\n",
       "│               ·                │\n",
       "│ Dodgeball|+00.70|+01.11|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.19|+01.13|-02.80 │\n",
       "│ Dodgeball|+00.70|+01.11|-02.80 │\n",
       "│ Dodgeball|+00.70|+01.11|-02.80 │\n",
       "│ Dodgeball|+00.70|+01.11|-02.80 │\n",
       "├────────────────────────────────┤\n",
       "│ ? rows (>9999 rows, 20 shown)  │\n",
       "└────────────────────────────────┘"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT arg_1_id as '?b' FROM data WHERE arg_1_type = 'dodgeball' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIT"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_TABLE_PREFIX = \"temp_table_\"\n",
    "DEBUG = True\n",
    "\n",
    "class CommonSensePredicateStatisticsDatabse():\n",
    "    data: pd.DataFrame\n",
    "    domains: typing.List[str]\n",
    "    predicates: typing.List[str]\n",
    "    room_objects_cache: typing.Dict[str, typing.Set[str]]\n",
    "    # same_type_arg_cache: typing.Dict[str, typing.List[typing.Tuple[str, str, str, str]]]\n",
    "    trace_lengths_and_domains: typing.Dict[str, typing.Tuple[int, str]]\n",
    "    trace_lengths_and_domains_df: pl.DataFrame\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 cache_dir: typing.Union[str, pathlib.Path] = DEFAULT_CACHE_DIR,\n",
    "                 trace_names: typing.Sequence[str] = FULL_PARTICIPANT_TRACE_SET,\n",
    "                 cache_rules: typing.Optional[typing.Sequence[str]] = None,\n",
    "                 base_trace_path: typing.Union[str, pathlib.Path] = DEFAULT_BASE_TRACE_PATH,\n",
    "                 cache_filename_format: str = DEFAULT_CACHE_FILE_NAME_FORMAT,\n",
    "                 trace_lengths_filename_format: str = DEFAULT_TRACE_LENGTHS_FILE_NAME_FORMAT,\n",
    "                 in_progress_traces_filename_format: str = DEFAULT_IN_PROCESS_TRACES_FILE_NAME_FORMAT,\n",
    "                 force_trace_names_hash: typing.Optional[str] = None,\n",
    "                 temp_table_prefix: str = TEMP_TABLE_PREFIX,\n",
    "                 overwrite: bool = False, trace_hash_n_characters: int = 8):\n",
    "        \n",
    "        self.object_assignment_cache = {}\n",
    "        self.temp_table_index = 0\n",
    "        self.predicates = split_args_stats.predicates\n",
    "        self.trace_lengths_and_domains_df = split_args_stats.trace_lengths_and_domains_df\n",
    "        self.domains = split_args_stats.domains\n",
    "        self.max_length = self.trace_lengths_and_domains_df.select(pl.col('trace_length').max()).item()\n",
    "        self.temp_table_prefix = temp_table_prefix\n",
    "\n",
    "        # duckdb.create_function(\"empty_bitstring\", self.create_empty_bitstring_function(self.max_length), [], duckdb.typing.BIT)\n",
    "\n",
    "\n",
    "    def _predicate_key(self, predicate: str, args: typing.Sequence[str]) -> str:\n",
    "        return f\"{predicate}-({','.join(args)})\"\n",
    "\n",
    "    def _domain_key(self, domain: str):\n",
    "        if domain.endswith('few_new_objects'):\n",
    "            return 'few'\n",
    "        elif domain.endswith('semi_sparse_new_objects'):\n",
    "            return 'medium'\n",
    "        elif domain.endswith('many_new_objects'):\n",
    "            return 'many'\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized domain: {domain}\")\n",
    "\n",
    "    def _object_assignments(self, domain, variable_types, used_objects=[]):\n",
    "        '''\n",
    "        Wrapper around get_object_assignments in order to cache outputs\n",
    "        '''\n",
    "\n",
    "        key = (domain, tuple(variable_types), tuple(used_objects))\n",
    "        if key not in self.object_assignment_cache:\n",
    "            object_assignments = get_object_assignments(domain, variable_types, used_objects=used_objects)\n",
    "            self.object_assignment_cache[key] = object_assignments\n",
    "\n",
    "        return self.object_assignment_cache[key]\n",
    "\n",
    "    \n",
    "    def filter(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]):\n",
    "        temp_table_names = [t[0] for t in duckdb.sql('SHOW TABLES').fetchall() if t[0].startswith(self.temp_table_prefix)]\n",
    "        for table_name in temp_table_names:\n",
    "            duckdb.sql(f'DROP TABLE {table_name};')\n",
    "        \n",
    "        try:\n",
    "            self.temp_table_index = 0\n",
    "            outcome_table_name, _ = self._inner_filter(predicate, mapping)\n",
    "            n_traces = duckdb.sql(f\"SELECT COUNT(DISTINCT(trace_id)) FROM {outcome_table_name}\").fetchone()[0]  # type: ignore\n",
    "            n_intervals = duckdb.sql(f\"SELECT COUNT(*) FROM {outcome_table_name}\").fetchone()[0]  # type: ignore\n",
    "            n_total_states = duckdb.sql(f\"SELECT SUM(bit_count(string_intervals)) FROM {outcome_table_name}\").fetchone()[0] # type: ignore\n",
    "            return n_traces, n_intervals, n_total_states\n",
    "            \n",
    "        except PredicateNotImplementedException as e:\n",
    "            # TODO: decide what we return in this case, or if we pass it through and let the feature handle it\n",
    "            raise e\n",
    "        \n",
    "    def _table_name(self, index: int):\n",
    "        return f\"{self.temp_table_prefix}{index}\"\n",
    "    \n",
    "    def _next_temp_table_index(self):\n",
    "        self.temp_table_index += 1\n",
    "        return self.temp_table_index\n",
    "    \n",
    "    def _next_temp_table_name(self):\n",
    "        return self._table_name(self._next_temp_table_index())\n",
    "    \n",
    "    def create_empty_bitstring_function(self, length: int):\n",
    "        def empty_bitstring():\n",
    "            return '0' * length\n",
    "        \n",
    "        return empty_bitstring\n",
    "\n",
    "    def _handle_predicate(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]) -> typing.Tuple[pl.DataFrame, typing.Set[str]]:\n",
    "        predicate_name = extract_predicate_function_name(predicate)  # type: ignore\n",
    "\n",
    "        if predicate_name not in self.predicates:\n",
    "            raise PredicateNotImplementedException(predicate_name)\n",
    "\n",
    "        variables = extract_variables(predicate)  # type: ignore\n",
    "        used_variables = set(variables)\n",
    "\n",
    "        # Restrict the mapping to just the referenced variables and expand meta-types\n",
    "        relevant_arg_mapping = {}\n",
    "        for var in variables:\n",
    "            if var in mapping:\n",
    "                relevant_arg_mapping[var] = sum([META_TYPES.get(arg_type, [arg_type]) for arg_type in mapping[var]], [])\n",
    "\n",
    "            # This handles variables which are referenced directly, like the desk and bed\n",
    "            elif not var.startswith(\"?\"):\n",
    "                relevant_arg_mapping[var] = [var]\n",
    "\n",
    "        select_items = [\"trace_id\", \"domain\", \"string_intervals\"]\n",
    "        where_items = [f\"predicate='{predicate_name}'\"]\n",
    "        \n",
    "        for i, (arg_var, arg_types) in enumerate(relevant_arg_mapping.items()):\n",
    "            # if it can be the generic object type, we filter for it specifically\n",
    "            if GAME_OBJECT in arg_types:\n",
    "                where_items.append(f\"arg_{i + 1}_type NOT IN {tuple(GAME_OBJECT_EXCLUDED_TYPES)}\")\n",
    "                \n",
    "            else:\n",
    "                if len(arg_types) == 1:\n",
    "                    where_items.append(f\"arg_{i + 1}_type='{arg_types[0]}'\")\n",
    "                else:\n",
    "                    where_items.append(f\"arg_{i + 1}_type IN {tuple(arg_types)}\")\n",
    "\n",
    "            select_items.append(f\"arg_{i + 1}_id as '{arg_var}'\")\n",
    "\n",
    "        table_name = self._next_temp_table_name()\n",
    "        query = f\"CREATE TEMP TABLE {table_name} AS SELECT {', '.join(select_items)} FROM data WHERE {' AND '.join(where_items)};\"\n",
    "        if DEBUG: print(query)\n",
    "        duckdb.sql(query)\n",
    "        return table_name, used_variables\n",
    "\n",
    "    def _handle_and(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]) -> typing.Tuple[pl.DataFrame, typing.Set[str]]:\n",
    "        and_args = predicate[\"and_args\"]\n",
    "        if not isinstance(and_args, list):\n",
    "            and_args = [and_args]\n",
    "\n",
    "        table_names = []\n",
    "        used_variables_by_child = []\n",
    "        all_used_variables = set()\n",
    "\n",
    "        for and_arg in and_args:  # type: ignore\n",
    "            try:\n",
    "                sub_table_name, sub_used_variables = self._inner_filter(and_arg, mapping)\n",
    "                table_names.append(sub_table_name)\n",
    "                used_variables_by_child.append(sub_used_variables)\n",
    "                all_used_variables |= sub_used_variables\n",
    "\n",
    "            except PredicateNotImplementedException as e:\n",
    "                continue\n",
    "\n",
    "        if len(table_names) == 0:\n",
    "            raise PredicateNotImplementedException(\"All sub-predicates of the and were not implemented\")\n",
    "\n",
    "        if len(table_names) == 1:\n",
    "            return table_names[0], used_variables_by_child[0]\n",
    "        \n",
    "        select_items = [f\"{table_names[0]}.trace_id\", f\"{table_names[0]}.domain\"]\n",
    "        selected_variables = set()\n",
    "        string_intervals = []\n",
    "        join_clauses = []\n",
    "\n",
    "        for i, (sub_table_name, sub_used_variables) in enumerate(zip(table_names, used_variables_by_child)):\n",
    "            string_intervals.append(f\"{sub_table_name}.string_intervals\")\n",
    "\n",
    "            for variable in sub_used_variables:\n",
    "                if variable not in selected_variables:\n",
    "                    select_items.append(f'{sub_table_name}.\"{variable}\"')\n",
    "                    selected_variables.add(variable)\n",
    "            \n",
    "            if i > 0:\n",
    "                join_parts = [f\"INNER JOIN {sub_table_name} ON {table_names[0]}.trace_id={sub_table_name}.trace_id\"] \n",
    "\n",
    "                for j, (prev_table_name, prev_used_variables) in enumerate(zip(table_names[:i], used_variables_by_child[:i])):\n",
    "                    shared_variables = sub_used_variables & prev_used_variables\n",
    "                    join_parts.extend([f'{sub_table_name}.\"{v}\"={prev_table_name}.\"{v}\"' for v in shared_variables])\n",
    "\n",
    "                join_clauses.append(\" AND \".join(join_parts))\n",
    "\n",
    "        \n",
    "        select_items.append(f'({\" & \".join(string_intervals)}) AS string_intervals')\n",
    "\n",
    "        table_name = self._next_temp_table_name()\n",
    "        query = f\"CREATE TABLE {table_name} AS SELECT {', '.join(select_items)} FROM {table_names[0]} {' '.join(join_clauses)};\"\n",
    "        if DEBUG: print(query)\n",
    "        duckdb.sql(query)\n",
    "\n",
    "        self._cleanup_empty_assignments(table_name)        \n",
    "\n",
    "        return table_name, all_used_variables\n",
    "\n",
    "    def _cleanup_empty_assignments(self, table_name: str) -> None:\n",
    "        cleanup_query = f\"DELETE FROM {table_name} WHERE bit_count(string_intervals) = 0;\"\n",
    "        if DEBUG: print(cleanup_query)\n",
    "        duckdb.sql(cleanup_query)\n",
    "\n",
    "    def _handle_or(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]) -> typing.Tuple[pl.DataFrame, typing.Set[str]]:\n",
    "        or_args = predicate[\"or_args\"]\n",
    "        if not isinstance(or_args, list):\n",
    "            or_args = [or_args]\n",
    "\n",
    "        table_names = []\n",
    "        used_variables_by_child = []\n",
    "        all_used_variables = set()\n",
    "\n",
    "        for or_arg in or_args:  # type: ignore\n",
    "            try:\n",
    "                sub_table_name, sub_used_variables = self._inner_filter(or_arg, mapping)\n",
    "                table_names.append(sub_table_name)\n",
    "                used_variables_by_child.append(sub_used_variables)\n",
    "                all_used_variables |= sub_used_variables\n",
    "\n",
    "            except PredicateNotImplementedException as e:\n",
    "                continue\n",
    "\n",
    "        if len(table_names) == 0:\n",
    "            raise PredicateNotImplementedException(\"All sub-predicates of the por were not implemented\")\n",
    "        \n",
    "        if len(table_names) == 1:\n",
    "            return table_names[0], used_variables_by_child[0]\n",
    "\n",
    "        # Building this table to explicitly represent all potential assignments, instead of implicitly representing them as nulls\n",
    "        empty_intervals_table_name = self._build_potential_missing_values_table(mapping, list(all_used_variables))\n",
    "\n",
    "        table_names.insert(0, empty_intervals_table_name)\n",
    "        used_variables_by_child.insert(0, all_used_variables)\n",
    "\n",
    "        select_items = [f\"{table_names[0]}.trace_id\", f\"{table_names[0]}.domain\"]\n",
    "        selected_variables = set()\n",
    "        string_intervals = []\n",
    "        join_clauses = []\n",
    "\n",
    "        for i, (sub_table_name, sub_used_variables) in enumerate(zip(table_names, used_variables_by_child)):\n",
    "            string_intervals.append(f\"{sub_table_name}.string_intervals\")\n",
    "\n",
    "            for variable in sub_used_variables:\n",
    "                if variable not in selected_variables:\n",
    "                    select_items.append(f'{sub_table_name}.\"{variable}\"')\n",
    "                    selected_variables.add(variable)\n",
    "            \n",
    "            if i > 0:\n",
    "                join_parts = [f\"LEFT JOIN {sub_table_name} ON {table_names[0]}.trace_id={sub_table_name}.trace_id\"] \n",
    "\n",
    "                shared_variables = sub_used_variables & all_used_variables\n",
    "                join_parts.extend([f'{sub_table_name}.\"{v}\"={empty_intervals_table_name}.\"{v}\"' for v in shared_variables])\n",
    "\n",
    "                join_clauses.append(\" AND \".join(join_parts))\n",
    "\n",
    "        string_intervals_coalesce = [f\"COALESCE({si}, empty_bitstring())\" if i > 0 else si for i, si in enumerate(string_intervals)]\n",
    "        select_items.append(f'({\" | \".join(string_intervals_coalesce)}) AS string_intervals')\n",
    "\n",
    "        table_name = self._next_temp_table_name()\n",
    "        query = f\"CREATE TABLE {table_name} AS SELECT {', '.join(select_items)} FROM {table_names[0]} {' '.join(join_clauses)};\"\n",
    "        if DEBUG: print(query)\n",
    "        duckdb.sql(query)\n",
    "\n",
    "        self._cleanup_empty_assignments(table_name)\n",
    "\n",
    "        return table_name, all_used_variables\n",
    "        \n",
    "\n",
    "    def _build_potential_missing_values_table(self, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]], relevant_vars: typing.List[str]):\n",
    "        # For each trace ID, and each assignment of the vars that exist in the sub_predicate_df so far:\n",
    "        relevant_var_mapping = {var: mapping[var] if var.startswith(\"?\") else [var] for var in relevant_vars}\n",
    "        variable_types = tuple(tuple(relevant_var_mapping[var]) for var in relevant_var_mapping.keys())\n",
    "\n",
    "        # For each cartesian product of the valid assignments for those vars given the domain\n",
    "        possible_arg_assignments = [self._object_assignments(domain, variable_types) for domain in self.domains]\n",
    "\n",
    "        # TODO: if I decide to make the intervals for each trace as long as that trace, I need to revise the logic here to do that, too\n",
    "        possible_assignments_df = pl.DataFrame(dict(domain=self.domains, assignments=possible_arg_assignments, string_intervals=['0' * self.max_length] * len(self.domains)),\n",
    "                                                schema=dict(domain=pl.Categorical, assignments=pl.List(pl.List(pl.Categorical)), string_intervals=pl.Utf8))  # type: ignore\n",
    "\n",
    "        potential_missing_values_df = self.trace_lengths_and_domains_df.join(possible_assignments_df, how=\"left\", on=\"domain\")\n",
    "        potential_missing_values_df = potential_missing_values_df.explode('assignments').select(\n",
    "            'domain', 'trace_id', \n",
    "            pl.col(\"assignments\").list.to_struct(fields=relevant_vars), 'string_intervals').unnest('assignments')\n",
    "\n",
    "        table_name = self._next_temp_table_name()\n",
    "        if DEBUG: print(f\"Creating potential missing values table {table_name}\")\n",
    "\n",
    "        assignment_columns = \", \".join(f'\"{var}\" arg_id' for var in relevant_vars)\n",
    "        duckdb.sql(f\"CREATE TABLE {table_name}(domain domain, trace_id trace_id, {assignment_columns}, string_intervals BITSTRING)\");\n",
    "        duckdb.sql(f\"INSERT INTO {table_name} SELECT * FROM potential_missing_values_df;\")\n",
    "        # duckdb.sql(f\"ALTER TABLE {table_name} ALTER string_intervals TYPE BITSTRING\")\n",
    "        # for var in relevant_vars:\n",
    "        #     duckdb.sql(f'ALTER TABLE {table_name} ALTER \"{var}\" TYPE arg_id')\n",
    "\n",
    "        return table_name\n",
    "\n",
    "    def _handle_not(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]) -> typing.Tuple[pl.DataFrame, typing.Set[str]]:\n",
    "        try:\n",
    "            inner_table_name, used_variables = self._inner_filter(predicate[\"not_args\"], mapping)  # type: ignore\n",
    "        except PredicateNotImplementedException as e:\n",
    "            raise PredicateNotImplementedException(f\"Sub-predicate of the not ({e.args}) was not implemented\")\n",
    "\n",
    "\n",
    "        relevant_vars = list(used_variables)\n",
    "        potential_missing_values_table_name = self._build_potential_missing_values_table(mapping, relevant_vars)\n",
    "\n",
    "        # Now, for each possible combination of args on each trace / domain, 'intervals' will contain the truth intervals if\n",
    "        # they exist and null otherwise, and 'intervals_right' will contain the empty interval'\n",
    "        join_columns = [\"trace_id\"] + relevant_vars\n",
    "\n",
    "        select_items = [f\"{potential_missing_values_table_name}.trace_id\", f\"{potential_missing_values_table_name}.domain\"]\n",
    "        select_items.extend(f\"{potential_missing_values_table_name}.\\\"{var}\\\"\" for var in relevant_vars)\n",
    "        select_items.append(f\"(~( {potential_missing_values_table_name}.string_intervals | COALESCE({inner_table_name}.string_intervals, empty_bitstring()) )) AS string_intervals\")\n",
    "        \n",
    "        join_items = [f\"{potential_missing_values_table_name}.\\\"{column}\\\"={inner_table_name}.\\\"{column}\\\"\"  for column in join_columns]\n",
    "\n",
    "        table_name = self._next_temp_table_name()\n",
    "        query = f\"CREATE TABLE {table_name} AS SELECT {', '.join(select_items)} FROM {potential_missing_values_table_name} LEFT JOIN {inner_table_name} ON {' AND '.join(join_items)};\"\n",
    "        if DEBUG: print(query)\n",
    "        duckdb.sql(query)\n",
    "\n",
    "        self._cleanup_empty_assignments(table_name)\n",
    "\n",
    "        return table_name, used_variables\n",
    "\n",
    "    def _predicate_and_mapping_cache_key(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]], *args, **kwargs) -> str:\n",
    "        '''\n",
    "        Returns a string that uniquely identifies the predicate and mapping\n",
    "        '''\n",
    "        return ast_section_to_string(predicate, PREFERENCES) + \"_\" + str(mapping)\n",
    "\n",
    "\n",
    "    def _inner_filter(self, predicate: tatsu.ast.AST, mapping: typing.Dict[str, typing.Union[str, typing.List[str]]]) -> typing.Tuple[pl.DataFrame, typing.Set[str]]:\n",
    "        '''\n",
    "        Filters the data by the given predicate and mapping, returning a list of intervals in which the predicate is true\n",
    "        for each processed trace\n",
    "\n",
    "        Returns a dictionary mapping from the trace ID to a dictionary that maps from the set of arguments to a list of\n",
    "        intervals in which the predicate is true for that set of arguments\n",
    "        '''\n",
    "\n",
    "        predicate_rule = predicate.parseinfo.rule  # type: ignore\n",
    "\n",
    "        if predicate_rule == \"predicate\":\n",
    "            return self._handle_predicate(predicate, mapping)\n",
    "\n",
    "        elif predicate_rule == \"super_predicate\":\n",
    "            return self._inner_filter(predicate[\"pred\"], mapping)  # type: ignore\n",
    "\n",
    "        elif predicate_rule == \"super_predicate_and\":\n",
    "            return self._handle_and(predicate, mapping)\n",
    "\n",
    "        elif predicate_rule == \"super_predicate_or\":\n",
    "            return self._handle_or(predicate, mapping)\n",
    "\n",
    "        elif predicate_rule == \"super_predicate_not\":\n",
    "            return self._handle_not(predicate, mapping)\n",
    "\n",
    "        elif predicate_rule in [\"super_predicate_exists\", \"super_predicate_forall\", \"function_comparison\"]:\n",
    "            raise PredicateNotImplementedException(predicate_rule)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Error: Unknown rule '{predicate_rule}'\")\n",
    "        \n",
    "\n",
    "cspsd = CommonSensePredicateStatisticsDatabse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GRAMMAR_PATH = \"../dsl/dsl.ebnf\"\n",
    "grammar = open(DEFAULT_GRAMMAR_PATH).read()\n",
    "grammar_parser = typing.cast(tatsu.grammars.Grammar, tatsu.compile(grammar))\n",
    "\n",
    "game = open(get_project_dir() + '/reward-machine/games/ball_to_bin_from_bed.txt').read()\n",
    "game_ast = grammar_parser.parse(game)  # type: ignore\n",
    "\n",
    "block_stacking_game = open(get_project_dir() + '/reward-machine/games/block_stacking.txt').read()\n",
    "block_stacking_game_ast = grammar_parser.parse(block_stacking_game)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(not  (or    (agent_holds ?b)    (in_motion ?c) ))\n"
     ]
    }
   ],
   "source": [
    "# test_pred_desk_and = block_stacking_game_ast[3][1]['preferences'][1]['definition']['pref_body']['body']['exists_args']['at_end_pred']\n",
    "# ast_printer.ast_section_to_string(test_pred_desk_and, ast_parser.PREFERENCES)\n",
    "\n",
    "test_pred_or = block_stacking_game_ast[3][1]['preferences'][2]['definition']['pref_body']['body']['exists_args']['at_end_pred']\n",
    "print(ast_printer.ast_section_to_string(test_pred_or, ast_parser.PREFERENCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TEMP TABLE temp_table_1 AS SELECT trace_id, domain, string_intervals, arg_1_id as '?b' FROM data WHERE predicate='agent_holds' AND arg_1_type IN ('bridge_block', 'cube_block', 'cylindrical_block', 'flat_block', 'pyramid_block', 'tall_cylindrical_block', 'tall_rectangular_block', 'triangle_block');\n",
      "CREATE TEMP TABLE temp_table_2 AS SELECT trace_id, domain, string_intervals, arg_1_id as '?c' FROM data WHERE predicate='in_motion' AND arg_1_type='chair';\n",
      "Creating potential missing values table temp_table_3\n",
      "CREATE TABLE temp_table_4 AS SELECT temp_table_3.trace_id, temp_table_3.domain, temp_table_3.\"?b\", temp_table_3.\"?c\", (temp_table_3.string_intervals | COALESCE(temp_table_1.string_intervals, empty_bitstring()) | COALESCE(temp_table_2.string_intervals, empty_bitstring())) AS string_intervals FROM temp_table_3 LEFT JOIN temp_table_1 ON temp_table_3.trace_id=temp_table_1.trace_id AND temp_table_1.\"?b\"=temp_table_3.\"?b\" LEFT JOIN temp_table_2 ON temp_table_3.trace_id=temp_table_2.trace_id AND temp_table_2.\"?c\"=temp_table_3.\"?c\";\n",
      "DELETE FROM temp_table_4 WHERE bit_count(string_intervals) = 0;\n",
      "Creating potential missing values table temp_table_5\n",
      "CREATE TABLE temp_table_6 AS SELECT temp_table_5.trace_id, temp_table_5.domain, temp_table_5.\"?b\", temp_table_5.\"?c\", (~( temp_table_5.string_intervals | COALESCE(temp_table_4.string_intervals, empty_bitstring()) )) AS string_intervals FROM temp_table_5 LEFT JOIN temp_table_4 ON temp_table_5.\"trace_id\"=temp_table_4.\"trace_id\" AND temp_table_5.\"?b\"=temp_table_4.\"?b\" AND temp_table_5.\"?c\"=temp_table_4.\"?c\";\n",
      "DELETE FROM temp_table_6 WHERE bit_count(string_intervals) = 0;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(382, 10236, 359706286)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cspsd.filter(test_pred_or, {\"?b\": [\"block\"], \"?c\": [\"chair\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359706286"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"SELECT temp_table_3.trace_id, temp_table_3.domain, temp_table_3.\"top_drawer\", temp_table_3.\"?g\", \n",
    "(temp_table_3.string_intervals | COALESCE(temp_table_1.string_intervals, empty_bitstring()) | COALESCE(temp_table_2.string_intervals, empty_bitstring())) AS si,\n",
    "FROM temp_table_3 \n",
    "LEFT JOIN temp_table_1 ON temp_table_3.trace_id=temp_table_1.trace_id AND temp_table_1.\"top_drawer\"=temp_table_3.\"top_drawer\" AND temp_table_1.\"?g\"=temp_table_3.\"?g\" \n",
    "LEFT JOIN temp_table_2 ON temp_table_3.trace_id=temp_table_2.trace_id AND temp_table_2.\"top_drawer\"=temp_table_3.\"top_drawer\" \n",
    "\"\"\"\n",
    "\n",
    "# temp_table_3.string_intervals as si3, COALESCE(temp_table_1.string_intervals, empty_bitstring()) as si1, COALESCE(temp_table_2.string_intervals, empty_bitstring()) AS si2,\n",
    "# \n",
    "q2 = \"\"\"SELECT temp_table_3.trace_id, temp_table_3.domain, temp_table_3.\"top_drawer\", temp_table_3.\"?g\", \n",
    "(temp_table_3.string_intervals | COALESCE(temp_table_1.string_intervals, empty_bitstring()) | COALESCE(temp_table_2.string_intervals, empty_bitstring())) AS si,\n",
    "FROM temp_table_3 \n",
    "LEFT JOIN temp_table_1 ON temp_table_3.trace_id=temp_table_1.trace_id AND temp_table_1.\"top_drawer\"=temp_table_3.\"top_drawer\" AND temp_table_1.\"?g\"=temp_table_3.\"?g\" \n",
    "LEFT JOIN temp_table_2 ON temp_table_3.trace_id=temp_table_2.trace_id AND temp_table_2.\"top_drawer\"=temp_table_3.\"top_drawer\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Non-string object dtypes are not supported yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[509], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pldf \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mfrom_dataframe(split_args_df)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/polars/convert.py:771\u001b[0m, in \u001b[0;36mfrom_dataframe\u001b[0;34m(df, allow_copy)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    765\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow>=11.0.0 is required for converting a dataframe interchange object\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m to a Polars dataframe.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    769\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterchange\u001b[39;00m  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m pa_table \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49minterchange\u001b[39m.\u001b[39;49mfrom_dataframe(df, allow_copy\u001b[39m=\u001b[39;49mallow_copy)\n\u001b[1;32m    772\u001b[0m \u001b[39mreturn\u001b[39;00m from_arrow(pa_table, rechunk\u001b[39m=\u001b[39mallow_copy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/pyarrow/interchange/from_dataframe.py:86\u001b[0m, in \u001b[0;36mfrom_dataframe\u001b[0;34m(df, allow_copy)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(df, \u001b[39m\"\u001b[39m\u001b[39m__dataframe__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`df` does not support __dataframe__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m _from_dataframe(df\u001b[39m.\u001b[39;49m__dataframe__(allow_copy\u001b[39m=\u001b[39;49mallow_copy),\n\u001b[1;32m     87\u001b[0m                        allow_copy\u001b[39m=\u001b[39;49mallow_copy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/pyarrow/interchange/from_dataframe.py:109\u001b[0m, in \u001b[0;36m_from_dataframe\u001b[0;34m(df, allow_copy)\u001b[0m\n\u001b[1;32m    107\u001b[0m batches \u001b[39m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mget_chunks():\n\u001b[0;32m--> 109\u001b[0m     batch \u001b[39m=\u001b[39m protocol_df_chunk_to_pyarrow(chunk, allow_copy)\n\u001b[1;32m    110\u001b[0m     batches\u001b[39m.\u001b[39mappend(batch)\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_batches(batches)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/pyarrow/interchange/from_dataframe.py:143\u001b[0m, in \u001b[0;36mprotocol_df_chunk_to_pyarrow\u001b[0;34m(df, allow_copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is not unique\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m col \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mget_column_by_name(name)\n\u001b[0;32m--> 143\u001b[0m dtype \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39;49mdtype[\u001b[39m0\u001b[39m]\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39min\u001b[39;00m (\n\u001b[1;32m    145\u001b[0m     DtypeKind\u001b[39m.\u001b[39mINT,\n\u001b[1;32m    146\u001b[0m     DtypeKind\u001b[39m.\u001b[39mUINT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     DtypeKind\u001b[39m.\u001b[39mDATETIME,\n\u001b[1;32m    150\u001b[0m ):\n\u001b[1;32m    151\u001b[0m     columns[name] \u001b[39m=\u001b[39m column_to_array(col, allow_copy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/game-gen/lib/python3.10/site-packages/pandas/core/interchange/column.py:124\u001b[0m, in \u001b[0;36mPandasColumn.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m infer_dtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_col) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    118\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    119\u001b[0m             DtypeKind\u001b[39m.\u001b[39mSTRING,\n\u001b[1;32m    120\u001b[0m             \u001b[39m8\u001b[39m,\n\u001b[1;32m    121\u001b[0m             dtype_to_arrow_c_fmt(dtype),\n\u001b[1;32m    122\u001b[0m             Endianness\u001b[39m.\u001b[39mNATIVE,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNon-string object dtypes are not supported yet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype_from_pandasdtype(dtype)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Non-string object dtypes are not supported yet"
     ]
    }
   ],
   "source": [
    "pldf = pl.from_dataframe(split_args_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp_table_1', 'temp_table_2']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb.sql(\"CREATE TYPE predicate AS ENUM (SELECT predicate FROM split_args_df);\")\n",
    "# duckdb.sql(\"CREATE TYPE domain AS ENUM (SELECT domain FROM split_args_df);\")\n",
    "# duckdb.sql(\"CREATE TYPE trace_id AS ENUM (SELECT trace_id FROM split_args_df);\")\n",
    "# all_types = tuple([t for t in set(split_args_df.arg_1_type.unique()) | set(split_args_df.arg_2_type.unique()) if isinstance(t, str) ])\n",
    "# duckdb.sql(f\"CREATE TYPE arg_type AS ENUM {all_types};\")\n",
    "# all_ids = tuple([t for t in set(split_args_df.arg_1_id.unique()) | set(split_args_df.arg_2_id.unique()) if isinstance(t, str)])\n",
    "# duckdb.sql(f\"CREATE TYPE arg_id AS ENUM {all_ids};\")\n",
    "\n",
    "# duckdb.sql('ALTER TABLE test ALTER predicate TYPE predicate')\n",
    "# duckdb.sql('ALTER TABLE test ALTER domain TYPE domain')\n",
    "# duckdb.sql('ALTER TABLE test ALTER trace_id TYPE trace_id')\n",
    "# duckdb.sql('ALTER TABLE test ALTER arg_1_type TYPE arg_type')\n",
    "# duckdb.sql('ALTER TABLE test ALTER arg_2_type TYPE arg_type')\n",
    "# duckdb.sql('ALTER TABLE test ALTER arg_1_id TYPE arg_id')\n",
    "# duckdb.sql('ALTER TABLE test ALTER arg_2_id TYPE arg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────┬─────────┬─────────┬─────────┬───────┐\n",
      "│   column_name    │ column_type │  null   │   key   │ default │ extra │\n",
      "│     varchar      │   varchar   │ varchar │ varchar │ varchar │ int32 │\n",
      "├──────────────────┼─────────────┼─────────┼─────────┼─────────┼───────┤\n",
      "│ predicate        │ predicate   │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_1_id         │ arg_id      │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_1_type       │ arg_type    │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_2_id         │ arg_id      │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ arg_2_type       │ arg_type    │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ trace_id         │ trace_id    │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ domain           │ \"domain\"    │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ intervals        │ INTEGER[][] │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ string_intervals │ BIT         │ YES     │ NULL    │ NULL    │  NULL │\n",
      "└──────────────────┴─────────────┴─────────┴─────────┴─────────┴───────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duckdb.sql('DESCRIBE test').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ bit_count(((SELECT string_intervals FROM test WHERE (predicate = 'on') LIMIT 1) & (SELECT string_intervals FROM te…  │\n",
       "│                                                        int64                                                         │\n",
       "├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│                                                                                                                  675 │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT bit_count((SELECT string_intervals FROM test WHERE predicate='on' LIMIT 1) & (SELECT string_intervals FROM test WHERE predicate='on' OFFSET 100 LIMIT 1))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┐\n",
       "│  intervals  │\n",
       "│  int16[][]  │\n",
       "├─────────────┤\n",
       "│ [[0, 1612]] │\n",
       "└─────────────┘"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT intervals FROM test WHERE predicate='on' LIMIT 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5802"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_type = 'basketball'\n",
    "duckdb.sql(f\"SELECT count(*) FROM data WHERE (arg_1_type='{arg_type}' OR arg_2_type='{arg_type}')\").fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────────────────────────────┐\n",
       "│                val                 │\n",
       "│              varchar               │\n",
       "├────────────────────────────────────┤\n",
       "│ south_wall                         │\n",
       "│ building_27                        │\n",
       "│ CylinderBlock|-02.97|+01.62|-01.50 │\n",
       "│ Shelf|+03.13|+00.63|-00.56         │\n",
       "│ building_11                        │\n",
       "│ PyramidBlock|-02.96|+01.61|-02.44  │\n",
       "│ Mirror|+00.45|+01.49|+00.62        │\n",
       "│ Pencil|+03.07|+00.79|-01.79        │\n",
       "│ building_9                         │\n",
       "│ PyramidBlock|-02.95|+01.61|-02.66  │\n",
       "│                ·                   │\n",
       "│                ·                   │\n",
       "│                ·                   │\n",
       "│ BridgeBlock|-02.92|+00.26|-02.52   │\n",
       "│ TeddyBear|-02.60|+00.60|-00.42     │\n",
       "│ PyramidBlock|+01.13|+01.78|-02.89  │\n",
       "│ building_12                        │\n",
       "│ AlarmClock|-01.41|+00.60|+00.45    │\n",
       "│ Book|+02.83|+00.41|-00.01          │\n",
       "│ CylinderBlock|+00.93|+01.61|-02.89 │\n",
       "│ building_8                         │\n",
       "│ Drawer|-01.52|+00.14|+00.35        │\n",
       "│ Drawer|-01.52|+00.41|+00.35        │\n",
       "├────────────────────────────────────┤\n",
       "│        151 rows (20 shown)         │\n",
       "└────────────────────────────────────┘"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT val FROM (SELECT unnest(enum_range(NULL::arg_id)) as val) \")  # WHERE val='Shelf|-02.97|+01.53|-01.72' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits_df.select(pl.col('bits_1') & pl.col('bits_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_specific_names = set()\n",
    "for room, type_to_ids in SPECIFIC_NAMED_OBJECTS_BY_ROOM.items():\n",
    "    all_specific_names.update(type_to_ids.keys())\n",
    "\n",
    "specific_name_rows = split_args_df[(split_args_df.arg_1_type.isin(all_specific_names) | split_args_df.arg_2_type.isin(all_specific_names))].shape[0]\n",
    "total_rows = split_args_df.shape[0]\n",
    "print(f'{specific_name_rows} / {total_rows} ({specific_name_rows / total_rows * 100:.2f}%) rows have a specific name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_type_rows = split_args_df[(split_args_df.predicate == 'same_type')].shape[0]\n",
    "print(f'{same_type_rows} / {total_rows} ({same_type_rows / total_rows * 100:.2f}%) rows are for same_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in split_args_df.iterrows():\n",
    "    print(i, row.to_dict())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_args_df[(split_args_df.predicate == 'adjacent') & (split_args_df.arg_1_type == 'agent') & (split_args_df.arg_2_type == 'green_golfball')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_args_df[(split_args_df.predicate == 'same_type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['medium', 'medium', 'medium', ..., 'many', 'many', 'many'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_df = split_args_df[(split_args_df.arg_1_type == 'door') | (split_args_df.arg_1_type == 'door')]\n",
    "print(door_df.predicate.value_counts())\n",
    "print()\n",
    "for predicate in door_df.predicate.unique():\n",
    "    pred_df = door_df[door_df.predicate == predicate]\n",
    "    print(f'For predicate {predicate}:')\n",
    "    print(pred_df.arg_2_type.value_counts().iloc[:10])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tid in door_df[door_df.predicate == 'in_motion'].trace_id:\n",
    "    print(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_args_df[split_args_df.predicate == 'in_motion'].arg_1_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats._invert_intervals(regular_df[(regular_df.trace_id == trace_id) & (regular_df.predicate == 'in_motion') & (regular_df.arg_ids == (ball_id,))].intervals.values[0],\n",
    "                        stats.trace_lengths[trace_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_args_df[(split_args_df.trace_id == trace_id) & (split_args_df.predicate == 'in') & (split_args_df.arg_1_id == bin_id) & (split_args_df.arg_2_id == ball_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_not_in_motion_int = split_args_stats._invert_intervals(\n",
    "    split_args_df[(split_args_df.trace_id == trace_id) & (split_args_df.predicate == 'in_motion') & (split_args_df.arg_1_id == ball_id)].intervals.values[0],\n",
    "    split_args_stats.trace_lengths_and_domains[trace_id][0],\n",
    ")\n",
    "\n",
    "ball_not_in_motion_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_in_bin_int = split_args_df[(split_args_df.trace_id == trace_id) & (split_args_df.predicate == 'in') & (split_args_df.arg_1_id == bin_id) & (split_args_df.arg_2_id == ball_id)].intervals.values[0]\n",
    "\n",
    "split_args_stats._intersect_intervals(ball_in_bin_int, ball_not_in_motion_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_trace_split_args_df = split_args_df[split_args_df['trace_id'] == trace_id]\n",
    "\n",
    "single_trace_split_args_stats = compile_predicate_statistics_split_args.CommonSensePredicateStatisticsSplitArgs(cache_dir)\n",
    "single_trace_split_args_stats.data = pl.from_pandas(single_trace_split_args_df)\n",
    "single_trace_split_args_stats.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GRAMMAR_PATH = \"../dsl/dsl.ebnf\"\n",
    "grammar = open(DEFAULT_GRAMMAR_PATH).read()\n",
    "grammar_parser = typing.cast(tatsu.grammars.Grammar, tatsu.compile(grammar))\n",
    "\n",
    "game = open(compile_predicate_statistics.get_project_dir() + '/reward-machine/games/ball_to_bin_from_bed.txt').read()\n",
    "game_ast = grammar_parser.parse(game) \n",
    "\n",
    "test_pred_1 = game_ast[4][1]['preferences'][0]['definition']['forall_pref']['preferences']['pref_body']['body']['exists_args']['then_funcs'][1]['seq_func']['hold_pred']\n",
    "\n",
    "# should be: (and (not (in_motion ?b)) (in ?h ?b)))\n",
    "test_pred_2 = game_ast[4][1]['preferences'][0]['definition']['forall_pref']['preferences']['pref_body']['body']['exists_args']['then_funcs'][2]['seq_func']['once_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapping = {\"?b\": [\"ball\"], \"?h\": [\"hexagonal_bin\"]}\n",
    "test_out = single_trace_split_args_stats.filter(test_pred_2, test_mapping)\n",
    "test_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
