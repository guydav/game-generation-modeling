{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import difflib\n",
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tatsu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src import fitness_energy_utils as utils\n",
    "from src.fitness_energy_utils import NON_FEATURE_COLUMNS\n",
    "from src.ast_counter_sampler import *\n",
    "from src.ast_utils import cached_load_and_parse_games_from_file, load_games_from_file, _extract_game_id\n",
    "from src import ast_printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = open('../dsl/dsl.ebnf').read()\n",
    "grammar_parser = tatsu.compile(grammar)\n",
    "game_asts = list(cached_load_and_parse_games_from_file('../dsl/interactive-beta.pddl', grammar_parser, False, relative_path='..'))\n",
    "real_game_texts = [ast_printer.ast_to_string(ast, '\\n') for ast in game_asts]\n",
    "regrown_game_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples.pddl'))\n",
    "regrown_game_1024_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples-1024.pddl'))\n",
    "print(len(real_game_texts), len(regrown_game_texts), len(regrown_game_texts) / 98, len(regrown_game_1024_texts), len(regrown_game_1024_texts) / 98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game_index(game_name: str):\n",
    "    first_dash = game_name.find('-')\n",
    "    second_dash = game_name.find('-', first_dash + 1)\n",
    "    index = game_name[first_dash + 1:second_dash] if second_dash != -1 else game_name[first_dash + 1:]\n",
    "    return int(index)\n",
    "\n",
    "\n",
    "def extract_negative_index(game_name: str):\n",
    "    first_dash = game_name.find('-')\n",
    "    second_dash = game_name.find('-', first_dash + 1)\n",
    "    if second_dash == -1:\n",
    "        return -1\n",
    "    \n",
    "    third_dash = game_name.find('-', second_dash + 1)\n",
    "    index = game_name[second_dash + 1:third_dash]\n",
    "    return int(index)\n",
    "\n",
    "\n",
    "fitness_df = utils.load_fitness_data('../data/fitness_features_1024_regrowths.csv.gz')\n",
    "\n",
    "# fitness_df = fitness_df.assign(real=fitness_df.real.astype('int'), game_index=fitness_df.game_name.apply(extract_game_index), \n",
    "#                                negative_index= fitness_df.game_name.apply(extract_negative_index), fake=~fitness_df.real.astype('int'))\n",
    "# fitness_df = fitness_df.sort_values(by=['fake', 'game_index', 'negative_index'], ignore_index=True).reset_index(drop=True)\n",
    "# fitness_df.drop(columns=['Index', 'fake', 'game_index', 'negative_index'], inplace=True)\n",
    "print(fitness_df.src_file.unique())\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_BINARIZED_FEATURES_MODEL = True\n",
    "\n",
    "# if USE_BINARIZED_FEATURES_MODEL:\n",
    "#     model_path = '../models/cv_binarized_model_2023_01_20.pkl.gz'\n",
    "#     data_df = binarized_df\n",
    "# else:\n",
    "#     model_path = '../models/cv_fitness_model_2023_01_20.pkl.gz'\n",
    "#     data_df = filtered_fitness_df\n",
    "\n",
    "model_date_id = 'larger_features_2023_03_29'\n",
    "data_df = fitness_df\n",
    "cv_energy_model, feature_columns = utils.load_model_and_feature_columns(model_date_id)\n",
    "print(len(feature_columns))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram the weights to get a sense of what we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cv_energy_model.named_steps['fitness'].model.fc1.weight.data.detach().squeeze()  # type: ignore\n",
    "bias = cv_energy_model.named_steps['fitness'].model.fc1.bias.data.detach().squeeze()  # type: ignore\n",
    "print(f'Weights mean: {weights.mean():.4f}, std: {weights.std():.4f}, bias: {bias:.4f}')\n",
    "\n",
    "plt.hist(weights, bins=30)\n",
    "plt.title('Energy model weights')\n",
    "plt.xlabel('Weight magnitude')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "quantile_index = 0\n",
    "\n",
    "abs_weights = weights.abs()\n",
    "\n",
    "for magnitude in torch.linspace(0,abs_weights.max(), 5000):\n",
    "    n = torch.sum(abs_weights < magnitude).item()\n",
    "    if n / len(weights) >= quantiles[quantile_index]:\n",
    "        print(f'Approximately {quantiles[quantile_index] * 100}% ({n}, {n / len(weights) * 100:.2f}%) of the weights have magnitude < {magnitude:.4f}')\n",
    "        quantile_index += 1\n",
    "\n",
    "    if quantile_index >= len(quantiles):\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the top K features most and least predictive of real games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "top_features = torch.topk(weights, K)\n",
    "bottom_features = torch.topk(weights, K, largest=False)\n",
    "\n",
    "lines = []\n",
    "\n",
    "lines.append('### Features with largest negative weights (most predictive of real games):')\n",
    "for i in range(K):\n",
    "    lines.append(f'{i+1}. {feature_columns[bottom_features.indices[i]]} ({bottom_features.values[i]:.4f})')\n",
    "\n",
    "lines.append('### Features with largest positive weights (most predictive of fake games):')\n",
    "for i in range(K):\n",
    "    lines.append((f'{i+1}. {feature_columns[top_features.indices[i]]} ({top_features.values[i]:.4f})'))\n",
    "\n",
    "display(Markdown('\\n'.join(lines)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[feature_columns.index(c)]) for c in feature_columns if 'distance_arg_types' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.groupby('real').distance_arg_types_furniture_receptacles_setup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[feature_columns.index(c)]) for c in feature_columns if 'disjoint_seq_funcs_found' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(c, weights[feature_columns.index(c)]) for c in feature_columns if c.startswith('ast_ngram') and c.endswith('score')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of the values for each of the and bottom K features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_histograms(df: pd.DataFrame, weights: torch.Tensor, k: int = 10,\n",
    "    largest: bool = True, bins: int = 100, histogram_log_y: bool = True, \n",
    "    histogram_density: bool = True, layout: typing.Optional[typing.Tuple[int, int]] = None,\n",
    "    figsize: typing.Optional[typing.Tuple[float, float]] = None, \n",
    "    panel_width: float = 4, panel_height: float = 4, ylabel_once_per_row: bool = True,\n",
    "    subplots_adjust_params: typing.Optional[typing.Dict[str, float]] = None,\n",
    "    title_fontsize: int = 12, title_split_threshold: int = 25,\n",
    "    cm: plt.get_cmap('tab20') = plt.get_cmap('tab20')):  # type: ignore\n",
    "    \n",
    "    if layout is None:\n",
    "        largest_div = int(np.floor(k ** 0.5))\n",
    "        while k % largest_div != 0:\n",
    "            largest_div -= 1\n",
    "\n",
    "        layout = (largest_div, k // largest_div)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (layout[1] * panel_width, layout[0] * panel_height)\n",
    "\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "\n",
    "    top_k = torch.topk(weights, k, largest=largest)\n",
    "\n",
    "    for i in range(k):\n",
    "        feature_index = top_k.indices[i]\n",
    "        ax = axes[i // layout[1]][i % layout[1]]\n",
    "\n",
    "        real_values = df[df.real == 1][feature_columns[feature_index]].to_numpy()\n",
    "        synthetic_values = df[df.real == 0][feature_columns[feature_index]].to_numpy()\n",
    "\n",
    "        # print(f'Feature = 0 {(real_values == 0).mean() * 100:.2f}% of the time in real games, {(synthetic_values == 0).mean() * 100:.2f}% of the time in synthetic games')\n",
    "\n",
    "        ax.hist([real_values, synthetic_values], label=['Real games', 'Regrown games'], \n",
    "            stacked=False, density=histogram_density, bins=bins, color=[cm.colors[0], cm.colors[2]])  # type: ignore\n",
    "        ax.set_xlabel('Feature value')\n",
    "\n",
    "        if not ylabel_once_per_row or i % layout[1] == 0:\n",
    "            if histogram_density:\n",
    "                if histogram_log_y:\n",
    "                    ax.set_ylabel('log(Density)')\n",
    "                else:\n",
    "                    ax.set_ylabel('Density')\n",
    "            elif histogram_log_y:\n",
    "                ax.set_ylabel('log(Count)')\n",
    "            else:\n",
    "                ax.set_ylabel('Count')\n",
    "\n",
    "        if histogram_log_y:\n",
    "            ax.semilogy()\n",
    "        \n",
    "        title_feature = f'#{i + 1}: {feature_columns[feature_index]}'\n",
    "        title_weight = f'(weight: {top_k.values[i]:.4f})'\n",
    "        if len(title_feature) > title_split_threshold:\n",
    "            title_split_index = title_feature.find('_', title_split_threshold) + 1\n",
    "            if title_split_index == 0:\n",
    "                title_split_index = len(title_feature)\n",
    "            title = f'{title_feature[:title_split_index]}\\n{title_feature[title_split_index:]} {title_weight}'\n",
    "        else:\n",
    "            title = f'{title_feature}\\n{title_weight}'\n",
    "\n",
    "        ax.set_title(title, fontdict=dict(fontsize=title_fontsize))\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "    if subplots_adjust_params is not None:\n",
    "        plt.subplots_adjust(**subplots_adjust_params)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 20 features with the largest negative weights, that is, most predictive of real games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "plot_value_histograms(data_df, weights, k=k, largest=False, bins=20, histogram_log_y=False, histogram_density=True,\n",
    "    subplots_adjust_params=dict(hspace=0.4), title_fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 20 features with largest weights, that is, most predictive of a fake game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_histograms(data_df, weights, k=k, largest=True, bins=20,  histogram_log_y=False, histogram_density=True,\n",
    "    subplots_adjust_params=dict(hspace=0.4), title_fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with knocking out features below a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = utils.df_to_tensor(data_df, feature_columns)\n",
    "\n",
    "\n",
    "for threshold in (0, 0.1, 0.2, 0.3):\n",
    "    weights = cv_energy_model.named_steps['fitness'].model.fc1.weight.data.detach().squeeze()  # type: ignore\n",
    "    weights[weights.abs() < threshold] = 0\n",
    "    model_copy = copy.deepcopy(cv_energy_model)\n",
    "    model_copy.named_steps['fitness'].model.fc1.weight.data = weights.unsqueeze(0)  # type: ignore\n",
    "\n",
    "    print(f'With threshold = {threshold}:')\n",
    "    print(utils.evaluate_trained_model(model_copy, full_tensor, utils.default_multiple_scoring)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some top negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = utils.df_to_tensor(data_df, feature_columns)\n",
    "if 'wrapper' in cv_energy_model.named_steps: cv_energy_model.named_steps['wrapper'].eval()\n",
    "full_tensor_scores = cv_energy_model.transform(full_tensor).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_game_scores = full_tensor_scores[:, 0]\n",
    "print(f'Real game scores: {real_game_scores.mean():.4f} ± {real_game_scores.std():.4f}, min = {real_game_scores.min():.4f}, max = {real_game_scores.max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_energy_histogram(cv_energy_model, full_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_scores = full_tensor_scores[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = full_tensor_scores[:, 0]\n",
    "score_diffs = negatives_scores - positive_scores.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(score_diffs.ravel(), 10, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEGATIVES = 10\n",
    "for index in torch.topk(score_diffs.ravel(), N_NEGATIVES, largest=False).indices:\n",
    "    utils.evaluate_energy_contributions(cv_energy_model, full_tensor, index, \n",
    "        feature_columns, full_tensor, real_game_texts, regrown_game_1024_texts, display_features_diff=False, min_display_threshold=0.001)\n",
    "    \n",
    "    display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df.game_name == '5fefd5b2173bfbe890bc98ed-88-1012-nd-4-rd-14-rs-setup-sk-prior1', 'agent_holds_arg_types_other_setup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regrown_game_1024_texts[75 * 1024 + 1012])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we never need to load a featurizer for anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fitness_features import *\n",
    "with gzip.open('../models/fitness_featurizer_2023_03_22.pkl.gz', 'rb') as f:\n",
    "    featurizer = pickle.load(f)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast = grammar_parser.parse(regrown_game_1024_texts[75 * 1024 + 1012])\n",
    "r = featurizer.parse(ast, '', True, False)\n",
    "{k: v for k, v in r.items() if k.startswith('agent_holds') and k.endswith('setup')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = featurizer.parse(ast, '', True, True)\n",
    "{k: v for k, v in r.items() if k.startswith('agent_holds') and k.endswith('setup')}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the role of different variables on the difficulty of the negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_DIFFICULTY_COLUMNS = [\n",
    "    'game_name', 'regrowth_index', \n",
    "    'original_game_name', 'original_game_index', \n",
    "    'node_depth', 'regrowth_depth', \n",
    "    'regrowth_section', 'regrowth_sampler', \n",
    "    'score_diff'\n",
    "]\n",
    "\n",
    "def apply_and_concat(dataframe, field, func, column_names):\n",
    "    return pd.concat((\n",
    "        dataframe,\n",
    "        dataframe[field].apply(\n",
    "            lambda cell: pd.Series(func(cell), index=column_names))), axis=1)\n",
    "\n",
    "\n",
    "game_name_to_index = {game_name: i for i, game_name in enumerate(data_df.loc[data_df.real == 1, 'game_name'])}\n",
    "\n",
    "\n",
    "def extract_info_from_game_name(game_name: str):\n",
    "    i = utils._find_nth(game_name, '-', 2)\n",
    "    original_game_name, regrowth_info = game_name[:i], game_name[i + 1:]\n",
    "    regrowth_index, _, node_depth, _, regrowth_depth, _, regrowth_section, _, regrowth_sampler = regrowth_info.split('-')\n",
    "    regrowth_index = int(regrowth_index)\n",
    "    node_depth = int(node_depth)\n",
    "    regrowth_depth = int(regrowth_depth)\n",
    "    original_game_index = game_name_to_index[original_game_name]\n",
    "    score_diff = score_diffs[original_game_index, regrowth_index].item()\n",
    "    return [regrowth_index, original_game_name, original_game_index, node_depth, regrowth_depth, regrowth_section, regrowth_sampler, score_diff]\n",
    "\n",
    "\n",
    "negative_difficulty_df = data_df.loc[data_df.real == 0, ['game_name']]\n",
    "negative_difficulty_df = apply_and_concat(negative_difficulty_df, 'game_name', extract_info_from_game_name, NEGATIVE_DIFFICULTY_COLUMNS[1:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.groupby('regrowth_sampler').score_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_difficulty_df.groupby('regrowth_section').score_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem(x):\n",
    "    return np.std(x) / np.sqrt(len(x))\n",
    "\n",
    "regrowth_depth_impact = negative_difficulty_df.groupby('regrowth_depth').score_diff.agg(['mean', sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(regrowth_depth_impact.index.values, regrowth_depth_impact['mean'].values, 'o', linestyle='-')\n",
    "plt.errorbar(regrowth_depth_impact.index.values, regrowth_depth_impact['mean'].values, regrowth_depth_impact['sem'].values, linestyle='None')\n",
    "plt.xlabel('Regrown tree depth')\n",
    "plt.ylabel('Mean energy difference (lower is harder)')\n",
    "plt.title('Mean energy difference by regrown tree depth')\n",
    "# regrowth_depth_impact['mean']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b8c8d5c21b7aee7bd0053f69e9c255c013bbea7031fbef7e66d58dd46c0fa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
