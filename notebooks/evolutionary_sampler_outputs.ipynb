{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:36:29 - ast_utils - DEBUG    - Using cache folder: /Users/guydavidson/tmp/game_generation_cache\n",
      "2023-11-02 18:36:29 - src.ast_utils - DEBUG    - Using cache folder: /Users/guydavidson/tmp/game_generation_cache\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from argparse import Namespace\n",
    "import copy\n",
    "import gzip\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "import duckdb\n",
    "from IPython.display import display, Markdown, HTML  # type: ignore\n",
    "import matplotlib\n",
    "import matplotlib.axes\n",
    "import matplotlib.pyplot as plt\n",
    "from Levenshtein import distance as _edit_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import tatsu\n",
    "import tatsu.ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.ast_utils import _extract_game_id, deepcopy_ast, replace_child\n",
    "from src.ast_printer import ast_to_lines\n",
    "from src import fitness_energy_utils as utils\n",
    "from src.fitness_energy_utils import NON_FEATURE_COLUMNS\n",
    "from src.fitness_features import *\n",
    "from src.ast_counter_sampler import *\n",
    "from src.evolutionary_sampler import *\n",
    "from src import fitness_features_by_category, latest_model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:36:31 - ast_utils - INFO     - Loading from cache file: /Users/guydavidson/tmp/game_generation_cache/interactive-beta-cache.pkl.gz\n",
      "2023-11-02 18:36:32 - ast_utils - INFO     - Finished loading cache file: /Users/guydavidson/tmp/game_generation_cache/interactive-beta-cache.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grammar = open('../dsl/dsl.ebnf').read()\n",
    "grammar_parser = tatsu.compile(grammar)\n",
    "game_asts = list(cached_load_and_parse_games_from_file('../dsl/interactive-beta.pddl', grammar_parser, False, relative_path='..'))\n",
    "real_game_texts = [ast_printer.ast_to_string(ast, '\\n') for ast in game_asts]\n",
    "# regrown_game_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples.pddl'))\n",
    "# regrown_game_1024_texts = list(load_games_from_file('../dsl/ast-real-regrowth-samples-1024.pddl'))\n",
    "# print(len(real_game_texts), len(regrown_game_texts), len(regrown_game_texts) / 98, len(regrown_game_1024_texts), len(regrown_game_1024_texts) / 98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interactive-beta.pddl' 'ast-real-regrowth-samples-1024.pddl.gz']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>src_file</th>\n",
       "      <th>game_name</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>original_game_name</th>\n",
       "      <th>real</th>\n",
       "      <th>variables_defined_all</th>\n",
       "      <th>variables_defined_prop</th>\n",
       "      <th>variables_used_all</th>\n",
       "      <th>variables_used_prop</th>\n",
       "      <th>...</th>\n",
       "      <th>ast_ngram_constraints_n_4_score</th>\n",
       "      <th>ast_ngram_constraints_n_5_score</th>\n",
       "      <th>ast_ngram_terminal_n_2_score</th>\n",
       "      <th>ast_ngram_terminal_n_3_score</th>\n",
       "      <th>ast_ngram_terminal_n_4_score</th>\n",
       "      <th>ast_ngram_terminal_n_5_score</th>\n",
       "      <th>ast_ngram_scoring_n_2_score</th>\n",
       "      <th>ast_ngram_scoring_n_3_score</th>\n",
       "      <th>ast_ngram_scoring_n_4_score</th>\n",
       "      <th>ast_ngram_scoring_n_5_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>interactive-beta.pddl</td>\n",
       "      <td>6172feb1665491d1efbce164-0</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>6172feb1665491d1efbce164-0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965835</td>\n",
       "      <td>0.977530</td>\n",
       "      <td>0.968377</td>\n",
       "      <td>0.978806</td>\n",
       "      <td>0.979229</td>\n",
       "      <td>0.981369</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>0.962489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>interactive-beta.pddl</td>\n",
       "      <td>5f77754ba932fb2c4ba181d8-2</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>5f77754ba932fb2c4ba181d8-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972010</td>\n",
       "      <td>0.976522</td>\n",
       "      <td>0.964548</td>\n",
       "      <td>0.975590</td>\n",
       "      <td>0.974119</td>\n",
       "      <td>0.982116</td>\n",
       "      <td>0.904404</td>\n",
       "      <td>0.917146</td>\n",
       "      <td>0.966749</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>interactive-beta.pddl</td>\n",
       "      <td>614b603d4da88384282967a7-3</td>\n",
       "      <td>many-objects-room-v1</td>\n",
       "      <td>614b603d4da88384282967a7-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941851</td>\n",
       "      <td>0.970089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856664</td>\n",
       "      <td>0.906768</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.956323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>interactive-beta.pddl</td>\n",
       "      <td>5bc79f652885710001a0e82a-5</td>\n",
       "      <td>few-objects-room-v1</td>\n",
       "      <td>5bc79f652885710001a0e82a-5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985712</td>\n",
       "      <td>0.978548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>0.962489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>interactive-beta.pddl</td>\n",
       "      <td>614dec67f6eb129c3a77defd-6</td>\n",
       "      <td>medium-objects-room-v1</td>\n",
       "      <td>614dec67f6eb129c3a77defd-6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981814</td>\n",
       "      <td>0.977738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.973379</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>0.963877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index               src_file                   game_name  \\\n",
       "0      0  interactive-beta.pddl  6172feb1665491d1efbce164-0   \n",
       "1      1  interactive-beta.pddl  5f77754ba932fb2c4ba181d8-2   \n",
       "2      2  interactive-beta.pddl  614b603d4da88384282967a7-3   \n",
       "3      3  interactive-beta.pddl  5bc79f652885710001a0e82a-5   \n",
       "4      4  interactive-beta.pddl  614dec67f6eb129c3a77defd-6   \n",
       "\n",
       "              domain_name          original_game_name  real  \\\n",
       "0  medium-objects-room-v1  6172feb1665491d1efbce164-0     1   \n",
       "1    many-objects-room-v1  5f77754ba932fb2c4ba181d8-2     1   \n",
       "2    many-objects-room-v1  614b603d4da88384282967a7-3     1   \n",
       "3     few-objects-room-v1  5bc79f652885710001a0e82a-5     1   \n",
       "4  medium-objects-room-v1  614dec67f6eb129c3a77defd-6     1   \n",
       "\n",
       "   variables_defined_all  variables_defined_prop  variables_used_all  \\\n",
       "0                      1                     1.0                   1   \n",
       "1                      1                     1.0                   1   \n",
       "2                      1                     1.0                   1   \n",
       "3                      1                     1.0                   1   \n",
       "4                      1                     1.0                   1   \n",
       "\n",
       "   variables_used_prop  ...  ast_ngram_constraints_n_4_score  \\\n",
       "0                  1.0  ...                         0.965835   \n",
       "1                  1.0  ...                         0.972010   \n",
       "2                  1.0  ...                         0.941851   \n",
       "3                  1.0  ...                         0.985712   \n",
       "4                  1.0  ...                         0.981814   \n",
       "\n",
       "   ast_ngram_constraints_n_5_score  ast_ngram_terminal_n_2_score  \\\n",
       "0                         0.977530                      0.968377   \n",
       "1                         0.976522                      0.964548   \n",
       "2                         0.970089                      0.000000   \n",
       "3                         0.978548                      0.000000   \n",
       "4                         0.977738                      0.000000   \n",
       "\n",
       "   ast_ngram_terminal_n_3_score  ast_ngram_terminal_n_4_score  \\\n",
       "0                      0.978806                      0.979229   \n",
       "1                      0.975590                      0.974119   \n",
       "2                      0.000000                      0.000000   \n",
       "3                      0.000000                      0.000000   \n",
       "4                      0.000000                      0.000000   \n",
       "\n",
       "   ast_ngram_terminal_n_5_score  ast_ngram_scoring_n_2_score  \\\n",
       "0                      0.981369                     0.924171   \n",
       "1                      0.982116                     0.904404   \n",
       "2                      0.000000                     0.856664   \n",
       "3                      0.000000                     0.924171   \n",
       "4                      0.000000                     0.968944   \n",
       "\n",
       "   ast_ngram_scoring_n_3_score  ast_ngram_scoring_n_4_score  \\\n",
       "0                     0.962489                     1.000000   \n",
       "1                     0.917146                     0.966749   \n",
       "2                     0.906768                     0.949890   \n",
       "3                     0.962489                     1.000000   \n",
       "4                     0.973379                     0.974631   \n",
       "\n",
       "   ast_ngram_scoring_n_5_score  \n",
       "0                     1.000000  \n",
       "1                     0.973770  \n",
       "2                     0.956323  \n",
       "3                     1.000000  \n",
       "4                     0.963877  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_df = utils.load_fitness_data('../data/fitness_features_1024_regrowths.csv.gz')\n",
    "print(fitness_df.src_file.unique())\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = ast_parser.ASTSamplePostprocessor()\n",
    "postprocessed_real_game_texts = [ast_printer.ast_to_string(postprocessor(ast), '\\n') for ast in game_asts]  # type: ignore\n",
    "\n",
    "real_game_edit_distances = np.zeros((len(game_asts), len(game_asts)), dtype=int)\n",
    "for i, j in itertools.combinations(range(len(game_asts)), 2):\n",
    "    real_game_edit_distances[i, j] = real_game_edit_distances[j, i] = edit_distance(postprocessed_real_game_texts[i], postprocessed_real_game_texts[j])\n",
    "\n",
    "\n",
    "def edit_distance(first_game_text: str, second_game_text: str):\n",
    "    first_game_text = first_game_text[first_game_text.find(')', first_game_text.find('(:domain')) + 1:]\n",
    "    second_game_text = second_game_text[second_game_text.find(')', second_game_text.find('(:domain')) + 1:]\n",
    "    return _edit_distance(first_game_text, second_game_text)\n",
    "\n",
    "\n",
    "def find_nearest_real_game_indices(game, k: int = 3) -> typing.Tuple[np.ndarray, np.ndarray]:\n",
    "    game_str = ast_printer.ast_to_string(game, '\\n')\n",
    "    distances = np.array([edit_distance(game_str, real_game) for real_game in postprocessed_real_game_texts])\n",
    "    nearest_real_game_indices = np.argsort(distances)[:k]\n",
    "    return nearest_real_game_indices, distances[nearest_real_game_indices]\n",
    "\n",
    "\n",
    "def print_nearest_real_games(game, k: int = 3):\n",
    "    indices, distances = find_nearest_real_game_indices(game, k)\n",
    "    for i, (idx, d) in enumerate(zip(indices, distances)):\n",
    "        real_game_distances = real_game_edit_distances[idx]\n",
    "        nearest_distance_indices = np.argsort(real_game_distances)[1:k + 1]  # index 0 is the game itself\n",
    "        display(Markdown(f'### Nearest real game #{i + 1}:'))\n",
    "        display(Markdown(f'Edit distance to sample {d}, real game nearest neighbor distances {np.array2string(real_game_distances[nearest_distance_indices], separator=\", \")}):\\n'))\n",
    "        display(Markdown(f'```pddl\\n{real_game_texts[idx]}\\n```'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTOGRAMS_SUBPLOTS_ADJUST_PARAMS = dict(hspace=0.3)\n",
    "\n",
    "\n",
    "def plot_value_histograms(results_by_feature_name_and_value: typing.Dict[str, typing.Dict[int, typing.List[float]]],\n",
    "    bins: int = 20, histogram_log_y: bool = False, \n",
    "    histogram_density: bool = True, layout: typing.Optional[typing.Tuple[int, int]] = None,\n",
    "    figsize: typing.Optional[typing.Tuple[float, float]] = None, \n",
    "    panel_width: float = 4, panel_height: float = 4, ylabel_once_per_row: bool = True,\n",
    "    subplots_adjust_params: typing.Optional[typing.Dict[str, float]] = HISTOGRAMS_SUBPLOTS_ADJUST_PARAMS,\n",
    "    title_fontsize: int = 12, title_split_threshold: int = 25,\n",
    "    cm: plt.get_cmap('tab20') = plt.get_cmap('tab20')):  # type: ignore\n",
    "    \n",
    "    k = len(results_by_feature_name_and_value.keys())\n",
    "\n",
    "    if layout is None:\n",
    "        largest_div = int(np.floor(k ** 0.5))\n",
    "        while k % largest_div != 0:\n",
    "            largest_div -= 1\n",
    "\n",
    "        layout = (largest_div, k // largest_div)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (layout[1] * panel_width, layout[0] * panel_height)\n",
    "\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "\n",
    "    for i, feature_name in enumerate(results_by_feature_name_and_value.keys()):\n",
    "        if layout[0] == 1:\n",
    "            ax = axes[i]\n",
    "        else:\n",
    "            ax = axes[i // layout[1]][i % layout[1]]\n",
    "\n",
    "        values_with = results_by_feature_name_and_value[feature_name][1]\n",
    "        values_without = results_by_feature_name_and_value[feature_name][0]\n",
    "\n",
    "        # print(f'Feature = 0 {(real_values == 0).mean() * 100:.2f}% of the time in real games, {(synthetic_values == 0).mean() * 100:.2f}% of the time in synthetic games')\n",
    "\n",
    "        ax.hist([values_with, values_without], label=[f'1 (n={len(values_with)})', f'0 (n={len(values_without)})'], \n",
    "            stacked=False, density=histogram_density, bins=bins, color=[cm.colors[0], cm.colors[2]])  # type: ignore\n",
    "        ax.set_xlabel('Fitness value')\n",
    "\n",
    "        if not ylabel_once_per_row or i % layout[1] == 0:\n",
    "            if histogram_density:\n",
    "                if histogram_log_y:\n",
    "                    ax.set_ylabel('log(Density)')\n",
    "                else:\n",
    "                    ax.set_ylabel('Density')\n",
    "            elif histogram_log_y:\n",
    "                ax.set_ylabel('log(Count)')\n",
    "            else:\n",
    "                ax.set_ylabel('Count')\n",
    "\n",
    "        if histogram_log_y:\n",
    "            ax.semilogy()\n",
    "        \n",
    "        title = f'#{i + 1}: {feature_name}'\n",
    "        ax.set_title(title, fontdict=dict(fontsize=title_fontsize))\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "    if subplots_adjust_params is not None:\n",
    "        plt.subplots_adjust(**subplots_adjust_params)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_archive_fullness(model: MAPElitesSampler, mutually_exclusive_features: typing.Optional[typing.List[str]] = None,\n",
    "                             plot_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = None):\n",
    "    if plot_kwargs is None:\n",
    "        plot_kwargs = {}\n",
    "    \n",
    "    results_by_feature_name = {feature_name: defaultdict(list) for feature_name in model.map_elites_feature_names}\n",
    "    results_by_feature_count = defaultdict(list)\n",
    "\n",
    "    for key, fitness_value in model.fitness_values.items():\n",
    "        for feature_name, feature_value in model._key_to_feature_dict(key).items():\n",
    "            results_by_feature_name[feature_name][feature_value].append(fitness_value)\n",
    "\n",
    "        if isinstance(key, int):\n",
    "            key_bits = count_set_bits(key)\n",
    "        else:\n",
    "            key_bits = sum(k != 0 for k in key)\n",
    "\n",
    "        results_by_feature_count[key_bits].append(fitness_value)\n",
    "\n",
    "    display(Markdown(f'## Archive fullness analysis'))\n",
    "    display(Markdown(f'Ttoal of {len(model.fitness_values)} samples in archive, {len(model.map_elites_feature_names)} features'))\n",
    "    display(Markdown(f'### Results by feature'))\n",
    "    lines = []\n",
    "    for feature_name, results in results_by_feature_name.items():\n",
    "        lines.append(f'- {feature_name}:')\n",
    "        for feature_value in sorted(results.keys()):\n",
    "            value_results = results[feature_value]\n",
    "            lines.append(f'    - ={feature_value}: {np.mean(value_results):.3f} ± {np.std(value_results):.3f} (n={len(value_results)})')\n",
    "\n",
    "    display(Markdown('\\n'.join(lines)))\n",
    "\n",
    "    display(Markdown(f'### Results by set feature count'))\n",
    "    lines = []\n",
    "    for feature_count in sorted(results_by_feature_count.keys()):\n",
    "        value_results = results_by_feature_count[feature_count]\n",
    "        lines.append(f'- set-count={feature_count}: {np.mean(value_results):.3f} ± {np.std(value_results):.3f} (n={len(value_results)} / {math.comb(len(model.map_elites_feature_names), feature_count)})')\n",
    "\n",
    "    display(Markdown('\\n'.join(lines)))\n",
    "\n",
    "    plot_value_histograms(results_by_feature_name, **plot_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBPLOTS_ADJUST_PARAMS = dict(top=0.925)\n",
    "DEFAULT_IGNORE_METRICS = ['Timestamp']\n",
    "\n",
    "\n",
    "FIGURE_TEMPLATE = r'''\\begin{{figure}}[!htb]\n",
    "% \\vspace{{-0.225in}}\n",
    "\\centering\n",
    "\\includegraphics[width=\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "% \\vspace{{-0.2in}}\n",
    "\\end{{figure}}\n",
    "'''\n",
    "WRAPFIGURE_TEMPLATE = r'''\\begin{{wrapfigure}}{{r}}{{0.5\\linewidth}}\n",
    "\\vspace{{-.3in}}\n",
    "\\begin{{spacing}}{{1.0}}\n",
    "\\centering\n",
    "\\includegraphics[width=0.95\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "\\end{{spacing}}\n",
    "% \\vspace{{-.25in}}\n",
    "\\end{{wrapfigure}}'''\n",
    "\n",
    "SAVE_PATH_PREFIX = './figures'\n",
    "\n",
    "\n",
    "def save_plot(save_path, bbox_inches='tight', should_print=False):\n",
    "    if save_path is not None:\n",
    "        save_path_no_ext = os.path.splitext(save_path)[0]\n",
    "        if should_print:\n",
    "            print('Figure:\\n')\n",
    "            print(FIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "            print('\\nWrapfigure:\\n')\n",
    "            print(WRAPFIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "            print('')\n",
    "        \n",
    "        if not save_path.startswith(SAVE_PATH_PREFIX):\n",
    "            save_path = os.path.join(SAVE_PATH_PREFIX, save_path)\n",
    "        \n",
    "        save_path = os.path.abspath(save_path)\n",
    "        folder, filename = os.path.split(save_path)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=bbox_inches, facecolor=plt.gcf().get_facecolor(), edgecolor='none')\n",
    "\n",
    "\n",
    "\n",
    "def plot_sampler_fitness_trajectory(\n",
    "        evo: PopulationBasedSampler, title: typing.Optional[str] = None, \n",
    "        axsize: typing.Tuple[int, int] = (8, 6),\n",
    "        plot_metrics: typing.Optional[bool] = None, \n",
    "        ignore_metrics: typing.Optional[typing.List[str]] = DEFAULT_IGNORE_METRICS,\n",
    "        subplots_adjust_params: typing.Dict[str, float] = SUBPLOTS_ADJUST_PARAMS,\n",
    "        min_real_game_fitness: typing.Optional[float] = None, max_real_game_fitness: typing.Optional[float] = None,\n",
    "        mean_real_game_fitness: typing.Optional[float] = None, \n",
    "        vertical: bool = True,\n",
    "        fontsize: int = 16,\n",
    "        save_path: typing.Optional[str] = None): \n",
    "    \n",
    "    if min_real_game_fitness is None or max_real_game_fitness is None:\n",
    "        raise ValueError('min_real_game_fitness and max_real_game_fitness must be specified')\n",
    "\n",
    "    if plot_metrics is None:\n",
    "        plot_metrics = hasattr(evo, 'archive_metrics_history') and len(evo.archive_metrics_history) > 0  # type: ignore\n",
    "\n",
    "    if ignore_metrics is None:\n",
    "        ignore_metrics = []\n",
    "    \n",
    "    if not plot_metrics:\n",
    "        layout = (1, 1)\n",
    "    elif vertical:\n",
    "        layout = (2, 1)\n",
    "    else:\n",
    "        layout = (1, 2)\n",
    "\n",
    "    figsize = (axsize[0] * layout[1], axsize[1] * layout[0])\n",
    "\n",
    "    fig, axes = plt.subplots(*layout, figsize=figsize)\n",
    "\n",
    "    mean, max_fit, std = [], [], []\n",
    "    for step_dict in evo.fitness_metrics_history:\n",
    "        mean.append(step_dict['mean'])\n",
    "        max_fit.append(step_dict['max'])\n",
    "        std.append(step_dict['std'])\n",
    "\n",
    "    mean = np.array(mean)\n",
    "    max_fit = np.array(max_fit)\n",
    "    std = np.array(std)\n",
    "\n",
    "    fitness_ax = typing.cast(matplotlib.axes.Axes, axes[0] if plot_metrics else axes)\n",
    "\n",
    "    fitness_ax.plot(mean, label='MAP-Elites fitness mean')\n",
    "    fitness_ax.fill_between(np.arange(len(mean)), mean - std, mean + std, alpha=0.2, label='MAP-Elites fitness std')  # type; ignore\n",
    "    fitness_ax.plot(max_fit, label='MAP-Elites fitness max')\n",
    "\n",
    "    fitness_ax.hlines(min_real_game_fitness, 0, len(mean), label='Real game fitness range', color='black', ls='--')\n",
    "    fitness_ax.hlines(max_real_game_fitness, 0, len(mean), color='black', ls='--')\n",
    "\n",
    "    if mean_real_game_fitness is not None:\n",
    "        fitness_ax.hlines(mean_real_game_fitness, 0, len(mean), label='Real game fitness mean', color='black', ls=':')\n",
    "\n",
    "    fitness_ax.set_xlabel('Generation', fontsize=fontsize)\n",
    "    fitness_ax.set_ylabel('Fitness', fontsize=fontsize)\n",
    "\n",
    "    fitness_ax.legend(loc='best', fontsize=fontsize)\n",
    "    fitness_ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    \n",
    "    if plot_metrics:\n",
    "        metrics = {key: [] for key in evo.archive_metrics_history[0].keys() if key not in ignore_metrics}  # type: ignore\n",
    "        for step_dict in evo.archive_metrics_history:  # type: ignore\n",
    "            for key, value in step_dict.items():\n",
    "                if key in metrics:\n",
    "                    metrics[key].append(value)\n",
    "\n",
    "        metrics_ax = typing.cast(matplotlib.axes.Axes, axes[1])\n",
    "        for key, values in metrics.items():\n",
    "            metrics_ax.plot(values, label=key.title())\n",
    "\n",
    "        metrics_ax.set_xlabel('Generation', fontsize=fontsize)\n",
    "        metrics_ax.set_ylabel('Number of games reaching threshold', fontsize=fontsize)\n",
    "\n",
    "        metrics_ax.legend(loc='best', fontsize=fontsize)\n",
    "        metrics_ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "        plt.subplots_adjust(**subplots_adjust_params)\n",
    "        \n",
    "    if title is not None:\n",
    "        if plot_metrics:\n",
    "            plt.suptitle(title)\n",
    "        else:\n",
    "            plt.title(title)\n",
    "\n",
    "    if save_path is not None:\n",
    "        save_plot(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def count_games_above_fitness_threshold(evo: PopulationBasedSampler, threshold: float) -> int:\n",
    "    if isinstance(evo.fitness_values, dict):\n",
    "        fitness_values = evo.fitness_values.values()\n",
    "    else:\n",
    "        fitness_values = evo.fitness_values\n",
    "\n",
    "    return sum(1 for fitness in fitness_values if fitness >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPRESENTATIVE_GAME_INDICES = [26, 58, 42, 31, 48, 19, 14, 62, 93] \n",
    "\n",
    "WARNING_YELLOW_BG_COLOR = '#F1EB9C'\n",
    "\n",
    "GAME_INDEX = 0\n",
    "GAME_AST = 1\n",
    "GAME_FITNESS = 2\n",
    "GAME_KEY = 3\n",
    "SAMPLE_FITNESS = 4\n",
    "SAMPLE_AST = 5\n",
    "\n",
    "\n",
    "CUSTOM_BACKGROUND_COLOR_CLASSES = ('bg-info', 'bg-warning', 'bg-success', 'bg-danger', 'bg-primary', 'bg-secondary', 'bg-dark', 'bg-light')\n",
    "\n",
    "\n",
    "def _format_ast_for_html(ast, line_delimiter='<br>', increment='  ',):\n",
    "    return f'<pre><code>{ast_printer.ast_to_string(ast, line_delimiter, increment=increment)}</code></pre>'\n",
    "\n",
    "\n",
    "def make_representative_game_table(model: MAPElitesSampler, trace_filter_data: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "                                   representative_game_indices: typing.Optional[typing.List[int]] = REPRESENTATIVE_GAME_INDICES, \n",
    "                                   real_game_asts=game_asts, line_delimiter='<br>', increment='  ', tablefmt='unsafehtml'):\n",
    "    real_game_fitness_scores, real_game_fitness_features = zip(*[model._score_proposal(game, return_features=True) for game in real_game_asts])  # type: ignore\n",
    "    real_game_fitness_score_indices = np.argsort(real_game_fitness_scores)[::-1]  # type: ignore\n",
    "\n",
    "    # If not provided, take the highest fitness game in each cell\n",
    "    cells_occupied = set()\n",
    "    if representative_game_indices is None:\n",
    "        representative_game_indices = []\n",
    "\n",
    "        for real_game_index in real_game_fitness_score_indices:\n",
    "            real_game = real_game_asts[real_game_index]\n",
    "            real_game_key = model._features_to_key(real_game, real_game_fitness_features[real_game_index])\n",
    "            if real_game_key not in cells_occupied:\n",
    "                representative_game_indices.append(real_game_index)\n",
    "                cells_occupied.add(real_game_key)\n",
    "\n",
    "    rows = [[] for _ in range(6)]\n",
    "\n",
    "    for idx in representative_game_indices:\n",
    "        real_game_rank = np.where(real_game_fitness_score_indices == idx)[0][0]\n",
    "        rows[GAME_INDEX].append(f'Game #{idx} (fitness rank {real_game_rank})')\n",
    "\n",
    "        real_game_ast_str = _format_ast_for_html(real_game_asts[idx], line_delimiter=line_delimiter, increment=increment)\n",
    "        rows[GAME_AST].append(real_game_ast_str)\n",
    "\n",
    "        fitness = real_game_fitness_scores[idx]\n",
    "        rows[GAME_FITNESS].append(f'<strong>Real game fitness: {fitness:.4f}</<strong>')\n",
    "\n",
    "        real_game = real_game_asts[idx]\n",
    "        real_game_key = model._features_to_key(real_game, real_game_fitness_features[idx])\n",
    "        key_dict = model._key_to_feature_dict(real_game_key)\n",
    "        key_dict_str = '<br>'.join([f'<strong>Key {real_game_key}:</strong>'] + [f'{feature_name}: {feature_value}' for feature_name, feature_value in key_dict.items()])\n",
    "        rows[GAME_KEY].append(key_dict_str)\n",
    "\n",
    "        if real_game_key in model.population:\n",
    "            sample = model.population[real_game_key]\n",
    "            sample_fitness = model.fitness_values[real_game_key]\n",
    "            custom_class = 'placeholder'\n",
    "            postfix = ''\n",
    "\n",
    "            if trace_filter_data is not None and real_game_key in trace_filter_data['summary']:\n",
    "                sample_trace_filter_result = trace_filter_data['summary'][real_game_key]\n",
    "                postfix = f' (trace filter result: {sample_trace_filter_result})'\n",
    "                \n",
    "                if sample_trace_filter_result == -1:\n",
    "                    custom_class = 'bg-info'\n",
    "                \n",
    "                elif sample_trace_filter_result == 0:\n",
    "                    custom_class = 'bg-warning'\n",
    "\n",
    "                else:\n",
    "                    custom_class = 'bg-success'\n",
    "\n",
    "            rows[SAMPLE_FITNESS].append(f'<div class=\"{custom_class}\"><strong>Sample fitness: {sample_fitness:.4f}{postfix}</strong></div>')\n",
    "\n",
    "            sample_ast_str = _format_ast_for_html(sample, line_delimiter=line_delimiter, increment=increment)\n",
    "            rows[SAMPLE_AST].append(sample_ast_str)\n",
    "\n",
    "        else:\n",
    "            rows[SAMPLE_FITNESS].append('No sample found')\n",
    "            rows[SAMPLE_AST].append('N/A')\n",
    "\n",
    "    return tabulate.tabulate(rows, headers='firstrow', tablefmt=tablefmt)\n",
    "\n",
    "\n",
    "\n",
    "def make_samples_only_game_table(model: MAPElitesSampler, sample_keys: typing.List[KeyTypeAnnotation],\n",
    "                                 trace_filter_data: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "                                 line_delimiter='<br>', increment='  ', tablefmt='unsafehtml'):\n",
    "\n",
    "    rows = defaultdict(list)\n",
    "\n",
    "    for sample_key in sample_keys:\n",
    "        key_dict = model._key_to_feature_dict(sample_key)\n",
    "        key_dict_str = '<br>'.join([f'<strong>Key {sample_key}:</strong>'] + [f'{feature_name}: {feature_value}' for feature_name, feature_value in key_dict.items()])\n",
    "        rows[GAME_KEY].append(key_dict_str)\n",
    "\n",
    "        sample = model.population[sample_key]\n",
    "        sample_fitness = model.fitness_values[sample_key]\n",
    "        custom_class = 'placeholder'\n",
    "        postfix = ''\n",
    "\n",
    "        if trace_filter_data is not None and sample_key in trace_filter_data['summary']:\n",
    "            sample_trace_filter_result = trace_filter_data['summary'][sample_key]\n",
    "            postfix = f' (trace filter result: {sample_trace_filter_result})'\n",
    "            \n",
    "            if sample_trace_filter_result == -1:\n",
    "                custom_class = 'bg-info'\n",
    "            \n",
    "            elif sample_trace_filter_result == 0:\n",
    "                custom_class = 'bg-warning'\n",
    "\n",
    "            else:\n",
    "                custom_class = 'bg-success'\n",
    "\n",
    "        rows[SAMPLE_FITNESS].append(f'<div class=\"{custom_class}\"><strong>Sample fitness: {sample_fitness:.4f}{postfix}</strong></div>')\n",
    "\n",
    "        sample_ast_str = _format_ast_for_html(sample, line_delimiter=line_delimiter, increment=increment)\n",
    "        rows[SAMPLE_AST].append(sample_ast_str)\n",
    "\n",
    "    return tabulate.tabulate([rows[SAMPLE_FITNESS], rows[GAME_KEY], rows[SAMPLE_AST]], tablefmt=tablefmt)\n",
    "\n",
    "\n",
    "\n",
    "def make_representative_game_table_to_html(table_html: str, model_name: str, real_game_energy_range: typing.Tuple[float, float], output_path='representative_games.html'):\n",
    "    table_html = table_html.replace('<table>', '<table class=\"table table-striped table-bordered\">')\n",
    "    table_html = table_html.replace('<thead>', '<thead class=\"thead-dark\">')\n",
    "    table_html = table_html.replace('<th>', '<th scope=\"col\">')\n",
    "    for custom_class in CUSTOM_BACKGROUND_COLOR_CLASSES:\n",
    "        table_html = table_html.replace(f'<td><div class=\"{custom_class}\">', f'<td class=\"{custom_class}\"><div>')\n",
    "    \n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "        .table td, .table th {\n",
    "            min-width: 40em;\n",
    "            max-width: 60em;\n",
    "        }\n",
    "        pre {\n",
    "            white-space: pre-wrap;\n",
    "            max-height: 60em;\n",
    "            overflow: auto;\n",
    "            display: inline-block;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    html_template = f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
    "        <title>Representative games comparison</title>\n",
    "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">\n",
    "        {style}\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Representative games comparison for {model_name}</h1>\n",
    "            <h3>Real game energy range: min: {real_game_energy_range[0]:.4f}, max: {real_game_energy_range[1]:.4f}</h3>\n",
    "            Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            {table_html}\n",
    "        </div>\n",
    "        <script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\" integrity=\"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin=\"anonymous\"></script>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js\" integrity=\"sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q\" crossorigin=\"anonymous\"></script>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js\" integrity=\"sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl\" crossorigin=\"anonymous\"></script>\n",
    "    </body>\n",
    "    \"\"\"\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(html_template)\n",
    "\n",
    "\n",
    "def make_and_save_representative_game_table(model, model_name, real_game_energy_range: typing.Tuple[float, float],\n",
    "                                            trace_filter_data: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "                                            representative_game_indices=REPRESENTATIVE_GAME_INDICES, \n",
    "                                            real_game_asts=game_asts, line_delimiter='<br>', increment='  ', tablefmt='unsafehtml'):\n",
    "    table_html = make_representative_game_table(model, trace_filter_data=trace_filter_data, representative_game_indices=representative_game_indices, \n",
    "                                                real_game_asts=real_game_asts, line_delimiter=line_delimiter, increment=increment, tablefmt=tablefmt)\n",
    "\n",
    "    prefix = 'representative_games' if representative_game_indices is not None else 'all_representative_games'\n",
    "    output_path = f'./output_htmls/{prefix}_{model.output_name}_{datetime.now().strftime(\"%Y_%m_%d\")}.html'\n",
    "    print(f'Saving representative games table to {os.path.abspath(output_path)}')\n",
    "    make_representative_game_table_to_html(table_html, model_name, real_game_energy_range, output_path)\n",
    "\n",
    "\n",
    "def plot_fitness_trajectory_and_make_game_table(model: MAPElitesSampler, title: str, \n",
    "                                                representative_game_indices=REPRESENTATIVE_GAME_INDICES, \n",
    "                                                save_path: typing.Optional[str] = None, \n",
    "                                                make_table: bool = True, plot_metrics: typing.Optional[bool] = None):\n",
    "    min_real_game_fitness =  -1 * model.fitness_function.score_dict['max']\n",
    "    max_real_game_fitness = -1 * model.fitness_function.score_dict['min']\n",
    "    mean_real_game_fitness = -1 * model.fitness_function.score_dict['mean']\n",
    "    plot_sampler_fitness_trajectory(model, title, plot_metrics=plot_metrics,\n",
    "                                    min_real_game_fitness=min_real_game_fitness, \n",
    "                                    max_real_game_fitness=max_real_game_fitness, \n",
    "                                    mean_real_game_fitness=mean_real_game_fitness,\n",
    "                                    save_path=save_path)\n",
    "    if make_table:\n",
    "        make_and_save_representative_game_table(model, title, \n",
    "                                                real_game_energy_range=(min_real_game_fitness, max_real_game_fitness),\n",
    "                                                representative_game_indices=representative_game_indices)\n",
    "\n",
    "\n",
    "def make_and_save_samples_game_table(model, model_name, sample_keys: typing.Optional[typing.List[KeyTypeAnnotation]] = None,\n",
    "                                     n_top_samples: int = 10, \n",
    "                                     trace_filter_data: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "                                     real_game_asts=game_asts, line_delimiter='<br>', increment='  ', tablefmt='unsafehtml'):\n",
    "    \n",
    "    if sample_keys is None:\n",
    "        real_game_fitness_features = [model._proposal_to_features(game) for game in real_game_asts]\n",
    "        cells_occupied = set([model._features_to_key(game, features) for game, features in zip(real_game_asts, real_game_fitness_features)])\n",
    "\n",
    "        sample_keys = []\n",
    "        fitness_values_and_keys = [(fitness, key) for key, fitness in model.fitness_values.items()]\n",
    "        fitness_values_and_keys.sort(reverse=True)\n",
    "\n",
    "        for _, key in fitness_values_and_keys:\n",
    "            if key not in cells_occupied:\n",
    "                sample_keys.append(key)\n",
    "                cells_occupied.add(key)\n",
    "\n",
    "            if len(sample_keys) >= n_top_samples:\n",
    "                break\n",
    "    \n",
    "    table_html = make_samples_only_game_table(model, sample_keys, trace_filter_data=trace_filter_data, \n",
    "                                              line_delimiter=line_delimiter, increment=increment, tablefmt=tablefmt)\n",
    "\n",
    "    prefix = 'map_elites_samples'\n",
    "    output_path = f'./output_htmls/{prefix}_{model.output_name}_{datetime.now().strftime(\"%Y_%m_%d\")}.html'\n",
    "    print(f'Saving representative games table to {os.path.abspath(output_path)}')\n",
    "\n",
    "    min_real_game_fitness =  -1 * model.fitness_function.score_dict['max']\n",
    "    max_real_game_fitness = -1 * model.fitness_function.score_dict['min']\n",
    "    make_representative_game_table_to_html(table_html, model_name, (min_real_game_fitness, max_real_game_fitness), output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_GAME_HEADER = 0\n",
    "REAL_GAME_TEXT = 1\n",
    "REAL_GAME = 2\n",
    "MAP_ELITES_HEADER = 3\n",
    "MAP_ELITES_TEXT = 4\n",
    "MAP_ELITES_GAME = 5\n",
    "\n",
    "\n",
    "LATEX_GAME_TEMPLATE = r\"\"\"\n",
    "\\begin{{lstlisting}}[aboveskip=-0.4 \\baselineskip,belowskip=-0.8 \\baselineskip]\n",
    "{ast_string}\n",
    "\\end{{lstlisting}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "LATEX_TABLE_TEMPLATE = r\"\"\"\n",
    "\\begin{{table}}[!htbp]\n",
    "    \\caption{{\\TODO[insert caption here]}}\n",
    "    \\begin{{adjustbox}}{{center}}\n",
    "    \\begin{{tabular}}{{|p{{\\gamecolumnwidth}}|p{{\\gamecolumnwidth}}|p{{\\gamecolumnwidth}}|}}\n",
    "    \\toprule\n",
    "    {table_text}\n",
    "    \\bottomrule\n",
    "    \\end{{tabular}}\n",
    "    \\end{{adjustbox}}\n",
    "    \\TODO[Insert any text below the table, if desired]\n",
    "    \\label{{tab:{table_label}}}\n",
    "\\end{{table}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "LATEX_DESCRIPTION_ONLY_TABLE_TEMPLATE = r\"\"\"\n",
    "\\begin{{table}}[!htbp]\n",
    "    \\caption{{\\TODO[insert caption here]}}\n",
    "    \\begin{{adjustbox}}{{center}}\n",
    "    \\begin{{tabular}}{{|p{{\\textcolumnwidth}}|p{{\\textcolumnwidth}}|}}\n",
    "    \\toprule\n",
    "    \\textbf{{Real Games}} & \\textbf{{MAP-Elites Samples}} \\\\\n",
    "    \\midrule\n",
    "    {table_text}\n",
    "    \\bottomrule\n",
    "    \\end{{tabular}}\n",
    "    \\end{{adjustbox}}\n",
    "    \\TODO[Insert any text below the table, if desired]\n",
    "    \\label{{tab:{table_label}}}\n",
    "\\end{{table}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "LATEX_SAMPLE_DESCRIPTION_ONLY_TABLE_TEMPLATE = r\"\"\"\n",
    "\\begin{{table}}[!htbp]\n",
    "    \\caption{{\\TODO[insert caption here]}}\n",
    "    \\begin{{adjustbox}}{{center}}\n",
    "    \\begin{{tabular}}{{|p{{\\textcolumnwidth}}|}}\n",
    "    \\toprule\n",
    "    \\textbf{{Novel MAP-Elites Samples}} \\\\\n",
    "    \\midrule\n",
    "    {table_text}\n",
    "    \\bottomrule\n",
    "    \\end{{tabular}}\n",
    "    \\end{{adjustbox}}\n",
    "    \\TODO[Insert any text below the table, if desired]\n",
    "    \\label{{tab:{table_label}}}\n",
    "\\end{{table}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def _format_ast_for_latex(ast):\n",
    "    ast_lines = ast_to_lines(ast, increment='  ')\n",
    "    reformatted_lines = []\n",
    "    buffer = []\n",
    "\n",
    "    combining_lines = False\n",
    "    for line in ast_lines:\n",
    "        current_line_is_only_paren = line.strip() == ')'\n",
    "\n",
    "        if current_line_is_only_paren:\n",
    "            combining_lines = True\n",
    "            buffer.append(line)\n",
    "\n",
    "        elif combining_lines:\n",
    "            combining_lines = False\n",
    "            new_line = buffer[-1].replace(')', ')' * len(buffer))\n",
    "            reformatted_lines.append(new_line)\n",
    "\n",
    "            reformatted_lines.append(line)\n",
    "\n",
    "            buffer = []\n",
    "\n",
    "        else:\n",
    "            reformatted_lines.append(line)       \n",
    "\n",
    "    if len(buffer) > 0:\n",
    "        new_line = buffer[-1].replace(')', ')' * len(buffer))\n",
    "        reformatted_lines.append(new_line)\n",
    "\n",
    "    ast_string = '\\n'.join(reformatted_lines)\n",
    "\n",
    "    return LATEX_GAME_TEMPLATE.format(ast_string=ast_string)\n",
    "\n",
    "\n",
    "def make_representative_game_table_latex(model, table_label: str,\n",
    "                                            trace_filter_data: typing.Optional[typing.Dict[str, typing.Any]] = None,\n",
    "                                            real_game_descriptions: typing.Optional[typing.Dict[int, str]] = None,\n",
    "                                            map_elites_sample_descriptions: typing.Optional[typing.Dict[int, str]] = None,\n",
    "                                            representative_game_indices=REPRESENTATIVE_GAME_INDICES, \n",
    "                                            real_game_asts=game_asts, description_text_size: str = 'tiny'):\n",
    "    \n",
    "    rows = defaultdict(list)\n",
    "    \n",
    "    for idx in representative_game_indices:\n",
    "        real_game_ast = real_game_asts[idx] \n",
    "        real_game_fitness_score, real_game_features = model._score_proposal(real_game_ast, return_features=True)\n",
    "\n",
    "        real_game_key = model._features_to_key(real_game_ast, real_game_features)\n",
    "        rows[REAL_GAME_HEADER].append(f'\\\\textbf{{Real Game \\\\#{idx} (fitness {real_game_fitness_score:.4f})}}')\n",
    "        rows[REAL_GAME_TEXT].append(r'\\TODO[describe real game here]' if real_game_descriptions is None else f'{{\\\\{description_text_size} {real_game_descriptions[idx]} }}')\n",
    "        rows[REAL_GAME].append(_format_ast_for_latex(real_game_ast))\n",
    "\n",
    "        map_elites_game = model.population[real_game_key]\n",
    "        map_elites_fitness_score = model.fitness_values[real_game_key]\n",
    "        rows[MAP_ELITES_HEADER].append(f'\\\\textbf{{MAP-Elites Sample (fitness {map_elites_fitness_score:.4f})}}')\n",
    "        rows[MAP_ELITES_TEXT].append(r'\\TODO[describe MAP-Elites sample here]' if map_elites_sample_descriptions is None else f'{{\\\\{description_text_size} {map_elites_sample_descriptions[idx]} }}')\n",
    "        rows[MAP_ELITES_GAME].append(_format_ast_for_latex(map_elites_game))\n",
    "\n",
    "    table_rows = []\n",
    "    table_rows.append(' & '.join(rows[REAL_GAME_HEADER]) + r' \\\\')\n",
    "    table_rows.append('\\\\midrule')\n",
    "    table_rows.append(' & '.join(rows[REAL_GAME_TEXT]) + r' \\\\')\n",
    "    table_rows.append(' & '.join(rows[REAL_GAME]) + r' \\\\')\n",
    "    table_rows.append('\\\\midrule')\n",
    "    table_rows.append(' & '.join(rows[MAP_ELITES_HEADER]) + r' \\\\')\n",
    "    table_rows.append('\\\\midrule')\n",
    "    table_rows.append(' & '.join(rows[MAP_ELITES_TEXT]) + r' \\\\')\n",
    "    table_rows.append(' & '.join(rows[MAP_ELITES_GAME]) + r' \\\\')\n",
    "    \n",
    "    if table_label.startswith('tab:'):\n",
    "        table_label = table_label[4:]\n",
    "\n",
    "    table_text = '\\n'.join(table_rows)\n",
    "    return LATEX_TABLE_TEMPLATE.format(table_text=table_text, table_label=table_label)\n",
    "    \n",
    "\n",
    "def make_samples_only_table_latex(model, table_label: str, sample_keys: typing.List[KeyTypeAnnotation], \n",
    "                                  map_elites_sample_descriptions: typing.Optional[typing.Dict[KeyTypeAnnotation, str]] = None,\n",
    "                                  description_text_size: str = 'tiny'):\n",
    "    \n",
    "\n",
    "    rows = defaultdict(list)\n",
    "    for key in sample_keys:\n",
    "        sample = model.population[key]\n",
    "        fitness = model.fitness_values[key]\n",
    "        rows[0].append(f'\\\\textbf{{MAP-Elites Sample (fitness {fitness:.4f})}}')\n",
    "        rows[1].append(r'\\TODO[describe sample here]' if map_elites_sample_descriptions is None else f'{{\\\\{description_text_size} {map_elites_sample_descriptions[key]} }}')\n",
    "        rows[2].append(_format_ast_for_latex(sample))\n",
    "\n",
    "    table_rows = []\n",
    "    table_rows.append(' & '.join(rows[0]) + r' \\\\')\n",
    "    table_rows.append('\\\\midrule')\n",
    "    table_rows.append(' & '.join(rows[1]) + r' \\\\')\n",
    "    table_rows.append(' & '.join(rows[2]) + r' \\\\')\n",
    "\n",
    "    if table_label.startswith('tab:'):\n",
    "        table_label = table_label[4:]\n",
    "\n",
    "    table_text = '\\n'.join(table_rows)\n",
    "    return LATEX_TABLE_TEMPLATE.format(table_text=table_text, table_label=table_label)\n",
    "\n",
    "\n",
    "\n",
    "def make_descriptions_only_table_latex(table_label: str,\n",
    "        real_game_descriptions: typing.Dict[int, str],\n",
    "        map_elites_sample_descriptions: typing.Dict[int, str],\n",
    "        text_size: str = 'tiny',):\n",
    "    \n",
    "    midrule = \"\\\\midrule\"\n",
    "\n",
    "    rows = [\n",
    "        f'{{ \\\\{text_size} {real_game_descriptions[index]} }} &  {{ \\\\{text_size} {map_elites_sample_descriptions[index]} }} \\\\\\\\ {midrule if i < len(real_game_descriptions) - 1 else \"\"}'\n",
    "        for i, index in enumerate(real_game_descriptions)\n",
    "    ]\n",
    "\n",
    "    table_text = '\\n'.join(rows)\n",
    "    return LATEX_DESCRIPTION_ONLY_TABLE_TEMPLATE.format(table_text=table_text, table_label=table_label)\n",
    "\n",
    "\n",
    "\n",
    "def make_samples_only_descriptions_only_table(table_label: str,\n",
    "                                              map_elites_sample_descriptions: typing.Dict[KeyTypeAnnotation, str],\n",
    "                                              text_size: str = 'tiny'):\n",
    "    \n",
    "    midrule = \"\\\\midrule\"\n",
    "\n",
    "    rows = [\n",
    "        f'{{ \\\\{text_size} {desc} }} \\\\\\\\ {midrule if i < len(map_elites_sample_descriptions) - 1 else \"\"}'\n",
    "        for i, (key, desc) in enumerate(map_elites_sample_descriptions.items())\n",
    "    ]\n",
    "\n",
    "    table_text = '\\n'.join(rows)\n",
    "    return LATEX_SAMPLE_DESCRIPTION_ONLY_TABLE_TEMPLATE.format(table_text=table_text, table_label=table_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FITNESS_COMPARISON_SCATTER_KWARGS = dict()\n",
    "FITNESS_COMPARISON_LINE_KWARGS = dict()\n",
    "FITNESS_COMPARISON_SUBPLOT_ADJUST_KWARGS = dict(hspace=0.3, wspace=0.1)\n",
    "\n",
    "\n",
    "def plot_fitness_comparison_across_bins(\n",
    "    models: typing.List[MAPElitesSampler],\n",
    "    real_game_bins_only: bool = True,\n",
    "    real_game_asts: typing.List[tuple] = game_asts,  # type: ignore\n",
    "    n_rows: typing.Optional[int] = None,\n",
    "    n_cols: typing.Optional[int] = None,\n",
    "    color_by_margin: bool = True,\n",
    "    underperforming_bin_threshold: int = 2,\n",
    "    color_in_margin: str = 'purple',\n",
    "    color_outside_margin: str = 'orange',\n",
    "    width_per_bin: float = 2,\n",
    "    height_per_bin: float = 2.5,\n",
    "    baseline_fontsize: int = 8,\n",
    "    scatter_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = FITNESS_COMPARISON_SCATTER_KWARGS,\n",
    "    line_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = FITNESS_COMPARISON_LINE_KWARGS,\n",
    "    subplot_adjust_kwargs: typing.Optional[typing.Dict[str, typing.Any]] = FITNESS_COMPARISON_SUBPLOT_ADJUST_KWARGS, \n",
    "):\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {}\n",
    "\n",
    "    if line_kwargs is None:\n",
    "        line_kwargs = {}\n",
    "\n",
    "    if subplot_adjust_kwargs is None:\n",
    "        subplot_adjust_kwargs = {}\n",
    "    \n",
    "    real_game_fitness_scores, real_game_features = zip(*[models[0]._score_proposal(game, return_features=True) for game in real_game_asts])  # type: ignore\n",
    "    real_game_iqr = np.percentile(real_game_fitness_scores, 75) - np.percentile(real_game_fitness_scores, 25)\n",
    "    real_game_keys = [models[0]._features_to_key(game, features) for game, features in zip(real_game_asts, real_game_features)]\n",
    "    bins_to_real_game_indices = defaultdict(list)\n",
    "    for idx, real_game_key in enumerate(real_game_keys):\n",
    "        bins_to_real_game_indices[real_game_key].append(idx)\n",
    "\n",
    "    if real_game_bins_only:\n",
    "        n_bins = len(bins_to_real_game_indices)\n",
    "        bins = list(sorted(bins_to_real_game_indices.keys()))\n",
    "        \n",
    "    else:\n",
    "        n_bins_by_model = [len(model.population) for model in models]\n",
    "        max_poulation_model_index = np.argmax(n_bins_by_model)\n",
    "        n_bins = n_bins_by_model[max_poulation_model_index]\n",
    "        bins = list(sorted(models[max_poulation_model_index].population.keys()))\n",
    "\n",
    "    if n_rows is not None and n_cols is not None:\n",
    "        assert n_rows * n_cols >= n_bins, f'Not enough rows and columns to fit {n_bins} bins'\n",
    "    elif n_rows is not None:\n",
    "        n_cols = math.ceil(n_bins / n_rows)\n",
    "    elif n_cols is not None:\n",
    "        n_rows = math.ceil(n_bins / n_cols)\n",
    "    else:\n",
    "        n_cols = math.ceil(math.sqrt(n_bins))\n",
    "        n_rows = math.ceil(n_bins / n_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * width_per_bin, n_rows * height_per_bin))\n",
    "\n",
    "    underperforming_bins = []\n",
    "\n",
    "    for bin_idx, bin_key in enumerate(bins):\n",
    "        ax = axes[bin_idx // n_cols, bin_idx % n_cols]\n",
    "        title = f'({\",\".join([str(x) for x in bin_key])})' if isinstance(bin_key, tuple) else str(bin_key)\n",
    "        \n",
    "        ax.set_yticks([])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=baseline_fontsize)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=baseline_fontsize - 2)\n",
    "\n",
    "        bin_fitness_values = [model.fitness_values[bin_key] for model in models]\n",
    "        \n",
    "        max_real_game_bin_fitness = None\n",
    "        if bin_key in bins_to_real_game_indices:\n",
    "            max_real_game_bin_fitness = max(real_game_fitness_scores[real_game_index] for real_game_index in bins_to_real_game_indices[bin_key])\n",
    "            for real_game_index in bins_to_real_game_indices[bin_key]:\n",
    "                real_game_fitness = real_game_fitness_scores[real_game_index]\n",
    "                ax.axvline(real_game_fitness, alpha=0.75 if real_game_fitness == max_real_game_bin_fitness else 0.25, **line_kwargs)\n",
    "\n",
    "        if color_by_margin and max_real_game_bin_fitness is not None:\n",
    "            # iqr_count = len([fitness for fitness in bin_fitness_values if fitness >= max_real_game_bin_fitness - real_game_iqr])\n",
    "            # title += f' (IQR: {iqr_count}/{len(bin_fitness_values)})'\n",
    "            games_within_margin = [fitness >= max_real_game_bin_fitness - real_game_iqr for fitness in bin_fitness_values]\n",
    "            if len(games_within_margin) - sum(games_within_margin) >= underperforming_bin_threshold:\n",
    "                underperforming_bins.append(bin_key)\n",
    "\n",
    "            c =  [color_in_margin if within_margin else color_outside_margin for within_margin in games_within_margin]\n",
    "        else:\n",
    "            c = color_outside_margin\n",
    "\n",
    "        ax.scatter(bin_fitness_values, np.arange(1, len(models) + 1), c=c, **scatter_kwargs)\n",
    "\n",
    "        ax.set_title(title, fontsize=baseline_fontsize + 2)\n",
    "\n",
    "    x_mins, x_maxes = zip(*[axes[bin_idx // n_cols, bin_idx % n_cols].get_xlim() for bin_idx in range(len(bins))])\n",
    "    x_min = min(x_mins)\n",
    "    x_max = max(x_maxes)\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "\n",
    "    for spare_bin_idx in range(len(bins), n_rows * n_cols):\n",
    "        ax = axes[spare_bin_idx // n_cols, spare_bin_idx % n_cols]\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(**subplot_adjust_kwargs)\n",
    "    plt.show()\n",
    "    return underperforming_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 18:36:36 - compile_predicate_statistics_full_database - INFO     - Loading data from files\n",
      "2023-11-02 18:36:58 - compile_predicate_statistics_full_database - INFO     - Creating DuckDB table...\n",
      "2023-11-02 18:37:00 - compile_predicate_statistics_full_database - INFO     - Creating data table indices...\n",
      "2023-11-02 18:37:19 - compile_predicate_statistics_full_database - INFO     - Loaded data, found 840475 rows\n"
     ]
    }
   ],
   "source": [
    "models, names = [], []\n",
    "\n",
    "for model_key, model_spec in latest_model_paths.MAP_ELITES_MODELS.items():\n",
    "    model = typing.cast(MAPElitesSampler, model_spec.load())\n",
    "    # plot_fitness_trajectory_and_make_game_table(model, model_spec.name)\n",
    "    models.append(model)\n",
    "    names.append(model_spec.name)\n",
    "\n",
    "# all_ngrams_uniform_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_L2_latest_setup_uniform_seed_42_gen_2048_2023_10_30'))\n",
    "# all_ngrams_uniform_l2_name = 'No \"Goodness\" BC | Uniform archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(all_ngrams_uniform_l2_model, all_ngrams_uniform_l2_name)\n",
    "# models.append(all_ngrams_uniform_l2_model)\n",
    "# names.append(all_ngrams_uniform_l2_name)\n",
    "\n",
    "# all_ngrams_uniform_new_bc_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_L2_latest_setup_expected_values_uniform_seed_42_gen_2048_2023_10_30'))\n",
    "# all_ngrams_uniform_new_bc_l2_name = 'Using New \"Goodness\" BC | Uniform archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(all_ngrams_uniform_new_bc_l2_model, all_ngrams_uniform_new_bc_l2_name)\n",
    "# models.append(all_ngrams_uniform_new_bc_l2_model)\n",
    "# names.append(all_ngrams_uniform_new_bc_l2_name)\n",
    "\n",
    "# exemplar_preferences_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_L2_exemplar_preferences_bc_setup_uniform_seed_42_gen_2048_2023_11_01'))\n",
    "# exemplar_preferences_l2_name = 'Exemplar Preferenecs BCs | No \"Goodness\" BC | Uniform archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(exemplar_preferences_l2_model, exemplar_preferences_l2_name)\n",
    "# models.append(exemplar_preferences_l2_model)\n",
    "# names.append(exemplar_preferences_l2_name)\n",
    "\n",
    "# exemplar_preferences_new_bc_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_L2_exemplar_preferences_bc_expected_values_uniform_seed_42_gen_2048_2023_10_31'))\n",
    "# exemplar_preferences_new_bc_l2_name = 'Exemplar Preferenecs BCs | Using New \"Goodness\" BC | Uniform archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(exemplar_preferences_new_bc_l2_model, exemplar_preferences_new_bc_l2_name)\n",
    "# models.append(exemplar_preferences_new_bc_l2_model)\n",
    "# names.append(exemplar_preferences_new_bc_l2_name)\n",
    "\n",
    "# all_ngrams_fitness_rank_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_L2_experimental_setup_fitness_rank_seed_42_final_2023_09_27'))\n",
    "# all_ngrams_fitness_rank_l2_name = 'All ngram features | Fitness rank archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(all_ngrams_fitness_rank_l2_model, all_ngrams_fitness_rank_l2_name)\n",
    "# models.append(all_ngrams_fitness_rank_l2_model)\n",
    "# names.append(all_ngrams_fitness_rank_l2_name)\n",
    "\n",
    "# full_ngram_only_uniform_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_full_ngram_only_L2_experimental_setup_uniform_seed_42_final_2023_09_27'))\n",
    "# full_ngram_only_uniform_l2_name = 'Full ngram feature only | Uniform archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(full_ngram_only_uniform_l2_model, full_ngram_only_uniform_l2_name)\n",
    "# models.append(full_ngram_only_uniform_l2_model)\n",
    "# names.append(full_ngram_only_uniform_l2_name)\n",
    "\n",
    "# full_ngram_only_fitness_rank_l2_model = typing.cast(MAPElitesSampler, utils.load_data('', 'samples', 'map_elites_minimal_counting_grammar_use_forall_full_ngram_only_L2_experimental_setup_fitness_rank_seed_42_final_2023_09_27'))\n",
    "# full_ngram_only_fitness_rank_l2_name = 'Full ngram feature only | Fitness rank archive sampling | L2 regularization'\n",
    "# plot_fitness_trajectory_and_make_game_table(full_ngram_only_fitness_rank_l2_model, full_ngram_only_fitness_rank_l2_name)\n",
    "# models.append(full_ngram_only_fitness_rank_l2_model)\n",
    "# names.append(full_ngram_only_fitness_rank_l2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_asts[0][4][1].preferences[0].definition.pref_body.body.exists_args.then_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(define (game 6172feb1665491d1efbce164-0) (:domain medium-objects-room-v1)\n",
      "(:setup\n",
      "  (exists (?h - hexagonal_bin ?r - triangular_ramp)\n",
      "    (game-conserved\n",
      "      (< (distance ?h ?r) 1)\n",
      "   )\n",
      " )\n",
      ")\n",
      "(:constraints\n",
      "  (and\n",
      "    (preference throwToRampToBin\n",
      "      (exists (?b - ball ?r - triangular_ramp ?h - hexagonal_bin)\n",
      "        (then\n",
      "          (once (agent_holds ?b))\n",
      "          (hold-while (and (not (agent_holds ?b)) (in_motion ?b)) (touch ?b ?r))\n",
      "          (once (and (not (in_motion ?b)) (in ?h ?b)))\n",
      "       )\n",
      "     )\n",
      "   )\n",
      "    (preference binKnockedOver\n",
      "      (exists (?h - hexagonal_bin)\n",
      "        (then\n",
      "          (once (object_orientation ?h upright))\n",
      "          (hold (and (not (touch agent ?h)) (not (agent_holds ?h))))\n",
      "          (once (not (object_orientation ?h upright)))\n",
      "       )\n",
      "     )\n",
      "   )\n",
      " )\n",
      ")\n",
      "(:terminal\n",
      "  (>= (count-once binKnockedOver) 1)\n",
      ")\n",
      "(:scoring\n",
      "  (count throwToRampToBin)\n",
      ")\n",
      ")\n",
      "10 8\n",
      "variable_list.variables | (?h - hexagonal_bin ?r - triangular_ramp)\n",
      "variable_list.variables | (?b - ball ?r - triangular_ramp ?h - hexagonal_bin)\n",
      "then.then_funcs | (then  (once (agent_holds ?b))  (hold-while (and (not (agent_holds ?b)) (in_motion ?b)) (touch ?b ?r))  (once (and (not (in_motion ?b)) (in ?h ?b))))\n",
      "super_predicate_and.and_args | (and  (not    (agent_holds ?b) )  (in_motion ?b))\n",
      "**while_hold.while_preds | (hold-while (and (not (agent_holds ?b)) (in_motion ?b)) (touch ?b ?r))**\n",
      "super_predicate_and.and_args | (and  (not    (in_motion ?b) )  (in ?h ?b))\n",
      "preferences.preferences | (and  (preference throwToRampToBin    (exists (?b - ball ?r - triangular_ramp ?h - hexagonal_bin)      (then        (once (agent_holds ?b))        (hold-while (and (not (agent_holds ?b)) (in_motion ?b)) (touch ?b ?r))        (once (and (not (in_motion ?b)) (in ?h ?b)))     )   ) )  (preference binKnockedOver    (exists (?h - hexagonal_bin)      (then        (once (object_orientation ?h upright))        (hold (and (not (touch agent ?h)) (not (agent_holds ?h))))        (once (not (object_orientation ?h upright)))     )   ) ))\n",
      "**variable_list.variables | (?h - hexagonal_bin)**\n",
      "then.then_funcs | (then  (once (object_orientation ?h upright))  (hold (and (not (touch agent ?h)) (not (agent_holds ?h))))  (once (not (object_orientation ?h upright))))\n",
      "super_predicate_and.and_args | (and  (not    (touch agent ?h) )  (not    (agent_holds ?h) ))\n"
     ]
    }
   ],
   "source": [
    "print(ast_printer.ast_to_string(game_asts[0], '\\n'))\n",
    "insert_nodes = models[-1]._get_valid_insert_or_delete_nodes(game_asts[0])[0]\n",
    "delete_nodes = models[-1]._get_valid_insert_or_delete_nodes(game_asts[0], insert=False)[0]\n",
    "print(len(insert_nodes), len(delete_nodes))\n",
    "# models[-1]._get_valid_insert_or_delete_nodes(game_asts[0])\n",
    "\n",
    "def node_info_to_str(node_info):\n",
    "    s = ast_printer.ast_section_to_string(node_info[0], node_info[2])\n",
    "    return f'{node_info[0].parseinfo.rule}.{node_info[1]} | {s}'\n",
    "\n",
    "insert_node_strs = [node_info_to_str(node_info) for node_info in insert_nodes]\n",
    "delete_node_strs = [node_info_to_str(node_info) for node_info in delete_nodes]\n",
    "\n",
    "for node_str in insert_node_strs:\n",
    "    if node_str not in delete_node_strs:\n",
    "        node_str = '**' + node_str + '**'\n",
    "    print(node_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_RATES = {\n",
    "    'gen_regrowth_sample': 0.5 / 5,\n",
    "    'insert': 0.5 / 5, \n",
    "    'delete': 0.5 / 5,\n",
    "    'crossover': 0.5 / 5,\n",
    "    'crossover_insert': 0.5 / 5,\n",
    "    'resample_variable_types': 0.4 / 5,\n",
    "    'resample_first_condition': 0.4 / 5,\n",
    "    'resample_last_condition': 0.4 / 5,\n",
    "    'resample_variable_types_and_first_condition': 0.4 / 5,\n",
    "    'resample_variable_types_and_last_condition': 0.4 / 5,\n",
    "    'sample_or_resample_setup': 0.1 / 4,\n",
    "    'sample_or_resample_terminal': 0.1 / 4,\n",
    "    'resample_scoring': 0.1 / 4,\n",
    "    '_crossover_full_sections': 0.1 / 4,\n",
    "}\n",
    "\n",
    "BASE_RATES.update({f'_{key}': value for key, value in BASE_RATES.items()})\n",
    "\n",
    "\n",
    "def plot_success_by_generation(model, normalize: bool = False, k: int = 5, normalize_base_rates: bool = True,\n",
    "                               base_rates: typing.Optional[typing.Dict[str, float]] = BASE_RATES,\n",
    "                               figsize: typing.Tuple[int, int] = (16, 12), fontsize: int = 16):\n",
    "    all_keys = set()\n",
    "    for step_success in model.success_by_generation_and_operator:\n",
    "        all_keys.update(step_success.keys())\n",
    "\n",
    "    all_keys = list(sorted(all_keys))\n",
    "    successes_by_ket = {key: np.zeros(len(model.success_by_generation_and_operator)) for key in all_keys}\n",
    "\n",
    "    for i, step_success in enumerate(model.success_by_generation_and_operator):\n",
    "        if normalize:\n",
    "            if normalize_base_rates:\n",
    "                step_success = {key: value / base_rates[key] for key, value in step_success.items()}\n",
    "\n",
    "            step_sum = sum(step_success.values())\n",
    "            step_success = {key: value / step_sum for key, value in step_success.items()}\n",
    "\n",
    "        for key in all_keys:\n",
    "            successes_by_ket[key][i] = step_success.get(key, 0)\n",
    "\n",
    "    kernel = np.ones(k) / k\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for key in all_keys:\n",
    "        smoothed_successes = np.convolve(successes_by_ket[key], kernel, mode='same')\n",
    "        updated_key = key.strip('_')\n",
    "        plt.plot(smoothed_successes, label=updated_key, alpha=0.75)\n",
    "\n",
    "    plt.xlabel('Generation', fontsize=fontsize)\n",
    "    plt.ylabel('Successes', fontsize=fontsize)\n",
    "    plt.legend(loc='best', fontsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_success_by_generation(models[-1], normalize=True, normalize_base_rates=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngrams_uniform_new_bc_l2_model.success_by_generation_and_operator[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fitness_trajectory_and_make_game_table(all_ngrams_uniform_new_bc_l2_model, None, representative_game_indices=None, save_path='map_elites_quantitative_reuslts_vertical_top_only.png', make_table=True, plot_metrics=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngrams_uniform_new_bc_l2_model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_game_descriptions = {\n",
    "    14: \"Build a `castle' by grabbing a bridge block, a flat block, a tall cylindrical block, a cube block, and a pyramid block, and stack them on top of each other in that order\",\n",
    "    42: \"Throw dodgeballs into the bin. You get a point for each made throw.\",\n",
    "    62: \"Set up the game by placing the hexagonal bin near the center of the room and all dodgeballs on the desk. To play, throw dodgeballs into the bin while standing next to the desk. You get a point for each made throw.\",\n",
    "    93: \"Set up the game by placing the dodgeball near the center of the room. To play the game, make a building on top of the doggie bed, without objects touching the floor or a wall. You get a point for each object in the building.\",\n",
    "}\n",
    "\n",
    "map_elites_sample_descriptions = {\n",
    "    14: \"Make buildings by grabbing a green bridge block, and placing any block and a pyramid block on it. The game ends once you make 12 such structures, and you get a point for each.\",\n",
    "    42: \"Throw beachballs into the bin. The game ends after you've made 22 throws or 5 throws with different beachballs. You get a point for each made throw.\",\n",
    "    62: \"Set up the game by placing the hexagonal bin very close to the top shelf. To play, put pink dodgeballs on the floor. Also, put the hexagonal bin upside down, and then flip to not be upside down without touching it or holding it. The game ends after you've put 8 pink dodgeballs on the floor or flipped the bin over 16 times. You get a point for each bin flip.\",\n",
    "    93: \"Set up the game by placing the hexagonal bin very close to the east wall. To play, put blue cube blocks on shelves adjacent to the west wall, and place orange objects closer to the rug than to the door. The game ends after you've placed 23 blue cube blocks or 20 different orange objects, and you get a point for each blue cube block placed.\"\n",
    "}\n",
    "\n",
    "\n",
    "print(make_representative_game_table_latex(\n",
    "    all_ngrams_uniform_new_bc_l2_model, 'comparison', \n",
    "    real_game_descriptions=real_game_descriptions,\n",
    "    map_elites_sample_descriptions=map_elites_sample_descriptions,\n",
    "    representative_game_indices=[42, 14, 93]))  # [42, 14, 62, 93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_descriptions_only_table_latex('comparison-descriptions', real_game_descriptions, map_elites_sample_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sample_keys = [\n",
    "    (1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1),\n",
    "    (1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0),\n",
    "    (1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1),\n",
    "    (1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0),\n",
    "    (1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1),\n",
    "    (0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1),\n",
    "    (1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1),\n",
    "]\n",
    "\n",
    "make_and_save_samples_game_table(all_ngrams_uniform_new_bc_l2_model, all_ngrams_uniform_new_bc_l2_name, sample_keys=candidate_sample_keys, n_top_samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_elites_novel_sample_descriptions = {\n",
    "    (1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1): \"Set up the game by placing the hexagonal bin very close to the rug. To play, start with it being in a diagonal orientation, and without touching it or holding it, get it to a different orientation. The game ends after you do so 14 times, and you get a point for each.\",\n",
    "    # (1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1): \"Throw yellow cube blocks. The game ends after you do so 10 times, and you get a point for each time.\",\n",
    "    (1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0): \"Place pillows on the bed and throw either dodgeballs or beach balls into the bin. The game ends after 5 succesful throws, and you get a point for each pillow on the bed.\",\n",
    "    (1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1): \"Find sets of four objects in the room, such that the second and third are the same color, the first is next to the second, and the first is inside the fourth. Additionally, throw dodgeballs or golf balls. The game ends after you've accomplished the first criterion twice, or thrown 3 different dodgeballs or golf balls. You get a point for each time you accomplish the first criterion.\",\n",
    "}\n",
    "\n",
    "\n",
    "print(make_samples_only_table_latex(all_ngrams_uniform_new_bc_l2_model, 'novel-samples', list(map_elites_novel_sample_descriptions.keys()), map_elites_novel_sample_descriptions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_samples_only_descriptions_only_table('novel-sample-texts', map_elites_novel_sample_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [r'{\\small', r'\\begin{itemize}']\n",
    "for desc in fitness_features_by_category.FITNESS_FEATURE_DESCRIPTIONS:\n",
    "    lines.append('\\t' + desc.to_latex())\n",
    "\n",
    "lines.append(r'\\end{itemize}')\n",
    "lines.append('}')\n",
    "\n",
    "print('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_model_indices = [0,] #  2]\n",
    "table_models = [models[idx] for idx in table_model_indices]\n",
    "table_names = [names[idx] for idx in table_model_indices]\n",
    "\n",
    "use_absolute_values = False\n",
    "\n",
    "weights_by_model = {}\n",
    "weight_ranks_by_model = {}\n",
    "\n",
    "for model, name in zip(table_models, table_names):\n",
    "    model_weights = model.fitness_function.named_steps['fitness'].model.fc1.weight.data.detach().squeeze()  # type: ignore\n",
    "    if use_absolute_values:\n",
    "        model_weights = torch.abs(model_weights)\n",
    "    model_weights_rank = stats.rankdata(model_weights.numpy())\n",
    "    if use_absolute_values:\n",
    "        model_weights_rank = len(model_weights_rank) - model_weights_rank + 1\n",
    "    weights_by_model[name] = {model.feature_names[i]: model_weights[i].item() for i in range(len(model.feature_names))}\n",
    "    weight_ranks_by_model[name] = {model.feature_names[i]: model_weights_rank[i] for i in range(len(model.feature_names))}\n",
    "\n",
    "\n",
    "feature_mean_rank = {\n",
    "    feature_name: np.mean([weights[feature_name] for weights in weight_ranks_by_model.values()])\n",
    "    for feature_name in weights_by_model[table_names[0]].keys()\n",
    "}\n",
    "\n",
    "feature_names_by_mean_rank = sorted(feature_mean_rank.keys(), key=lambda feature_name: feature_mean_rank[feature_name], reverse=False)\n",
    "\n",
    "headers = ['Feature', 'Mean Rank'] + table_names\n",
    "rows = [[feature_name, f'{feature_mean_rank[feature_name]:.3f}'] + [f'{weights_by_model[name][feature_name]:.3f} ({int(weight_ranks_by_model[name][feature_name])})'   \n",
    "                          for name in table_names] \n",
    "        for feature_name in feature_names_by_mean_rank]\n",
    "\n",
    "# with open('temp_outputs/features_by_mean_weight.tsv', 'w') as f:\n",
    "#     f.write(tabulate.tabulate(rows, headers, tablefmt='tsv'))\n",
    "\n",
    "print(tabulate.tabulate(rows, headers, tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_pairwise_edit_distances(model: MAPElitesSampler):\n",
    "#     population_as_strings = {key: ast_printer.ast_to_string(ast) for key, ast in tqdm(model.population.items(), desc='Stringifying population')}  # type: ignore\n",
    "#     population_keys = list(model.population.keys())\n",
    "#     distances = []\n",
    "#     total_combinations = len(population_keys) * (len(population_keys) - 1) / 2\n",
    "#     for first_key, second_key in tqdm(itertools.combinations(population_keys, 2), desc='Computing pairwise distances', total=total_combinations):\n",
    "#         distances.append(_edit_distance(population_as_strings[first_key], population_as_strings[second_key]))\n",
    "\n",
    "#     return np.mean(distances), np.std(distances), np.std(distances) / np.sqrt(total_combinations), len(population_as_strings), len(distances)\n",
    "        \n",
    "\n",
    "# model_edit_distances = {model.output_name: compute_pairwise_edit_distances(model) for model in models}\n",
    "\n",
    "# for name, distances in model_edit_distances.items():\n",
    "#     print(f'{name}: {distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_object_model_edit_distances = {model.output_name: compute_pairwise_edit_distances(model) for model in specific_object_models}\n",
    "\n",
    "# for name, distances in specific_object_model_edit_distances.items():\n",
    "#     print(f'{name}: {distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_pairwise_feature_distances(model: MAPElitesSampler, ord: int = 1):\n",
    "#     population_as_features = {key: model._proposal_to_features(ast) for key, ast in tqdm(model.population.items(), desc='Featurizing population')}  # type: ignore\n",
    "#     population_as_features = {key: np.array([features[n] for n in model.feature_names], dtype=float) for key, features in population_as_features.items()}\n",
    "#     population_keys = list(model.population.keys())\n",
    "#     distances = []\n",
    "#     total_combinations = len(population_keys) * (len(population_keys) - 1) / 2\n",
    "#     for first_key, second_key in tqdm(itertools.combinations(population_keys, 2), desc='Computing pairwise distances', total=total_combinations):\n",
    "#         distances.append(np.linalg.norm(population_as_features[first_key] - population_as_features[second_key], ord=ord))\n",
    "\n",
    "#     return np.mean(distances), np.std(distances), np.std(distances) / np.sqrt(total_combinations), len(population_as_features), len(distances)\n",
    "        \n",
    "\n",
    "# model_edit_distances = {model.output_name: compute_pairwise_feature_distances(model) for model in models}\n",
    "\n",
    "# for name, distances in model_edit_distances.items():\n",
    "#     print(f'{name}: {distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_object_model_edit_distances = {model.output_name: compute_pairwise_feature_distances(model) for model in specific_object_models}\n",
    "\n",
    "# for name, distances in specific_object_model_edit_distances.items():\n",
    "#     print(f'{name}: {distances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # models = [\n",
    "# #     predicate_and_object_groups_seed_33, \n",
    "# #     predicate_and_object_groups_seed_42,\n",
    "# #     predicate_and_object_groups_seed_66, \n",
    "# #     predicate_and_object_groups_seed_99\n",
    "# # ]\n",
    "\n",
    "\n",
    "# real_game_fitness_scores, real_game_features = zip(*[models[0]._score_proposal(game, return_features=True) for game in game_asts])  # type: ignore\n",
    "# real_game_keys = [models[0]._features_to_key(game, features) for game, features in zip(game_asts, real_game_features)]  # type: ignore\n",
    "# bins_to_real_game_indices = defaultdict(list)\n",
    "# for idx, real_game_key in enumerate(real_game_keys):\n",
    "#     bins_to_real_game_indices[real_game_key].append(idx)\n",
    "\n",
    "\n",
    "# # n_bins_by_model = [len(model.population) for model in models]\n",
    "# # max_poulation_model_index = np.argmax(n_bins_by_model)\n",
    "# # n_bins = n_bins_by_model[max_poulation_model_index]\n",
    "# # all_bins = list(sorted(models[max_poulation_model_index].population.keys()))\n",
    "\n",
    "# # scores_with_human_games = []\n",
    "# # scores_without_human_games = []\n",
    "\n",
    "# # for bin in all_bins:\n",
    "# #     target_list = scores_with_human_games if bin in bins_to_real_game_indices else scores_without_human_games\n",
    "# #     for model in models:\n",
    "# #         target_list.append(model.fitness_values[bin])\n",
    "\n",
    "# # print('With human games:', np.mean(scores_with_human_games), np.std(scores_with_human_games))\n",
    "# # print('Without human games:', np.mean(scores_without_human_games), np.std(scores_without_human_games))\n",
    "# # ttest_result = stats.ttest_ind(scores_with_human_games, scores_without_human_games)\n",
    "# # print('T-test:', ttest_result)\n",
    "\n",
    "\n",
    "# underperforming_bins = plot_fitness_comparison_across_bins(models, n_cols=7)\n",
    "# print(underperforming_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = ['Underperforming Bins'] + [f'#{i + 1}' for i in range(len(underperforming_bins))] + ['Sum', 'Overall Count', '%']\n",
    "\n",
    "# underperforming_feature_counts = {}\n",
    "# overall_feature_counts = {}\n",
    "\n",
    "# rows = []\n",
    "# for i, feature_name in enumerate(models[0].map_elites_feature_names):\n",
    "#     underperforming_bin_values = [bin[i] for bin in underperforming_bins]\n",
    "#     underperforming_feature_counts[feature_name] = sum(underperforming_bin_values)\n",
    "#     overall_feature_counts[feature_name] = sum([bin[i] for bin in bins_to_real_game_indices.keys()])\n",
    "\n",
    "#     proportion = f'{underperforming_feature_counts[feature_name] / overall_feature_counts[feature_name]:.2f}'\n",
    "#     row = [feature_name.replace('|', ' OR ')] + underperforming_bin_values + [underperforming_feature_counts[feature_name], overall_feature_counts[feature_name], proportion]\n",
    "#     rows.append(row)\n",
    "    \n",
    "\n",
    "\n",
    "# table = tabulate.tabulate(rows, headers=headers, tablefmt='github')\n",
    "\n",
    "# display(Markdown(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for bin in underperforming_bins:\n",
    "#     models[0].print_key_features(bin)\n",
    "#     for game_index in bins_to_real_game_indices[bin]:\n",
    "#         ast = game_asts[game_index]\n",
    "#         ast_str = ast_printer.ast_to_string(ast, '\\n')\n",
    "#         display(Markdown(f'```pddl\\n{ast_str}\\n```\\n'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = evo_sampler_map_elites_fitness_rank_no_at_end\n",
    "model = all_ngrams_uniform_l2_model\n",
    "index = 3\n",
    "n_features_on = None\n",
    "feature_keywords_to_print = None  # ['max_depth', 'mean_depth', 'node_count']\n",
    "n_similar_real_games_to_print = 3\n",
    "key_features = None  # dict(section_doesnt_exist_setup=0)\n",
    "\n",
    "sample_key = model.visualize_top_sample(index, feature_keywords_to_print=feature_keywords_to_print, n_features_on=n_features_on, \n",
    "    postprocess_sample=True, features=key_features)\n",
    "sample = model.population[sample_key] \n",
    "# print_nearest_real_games(sample, n_similar_real_games_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]\n",
    "sample_key =   (1, 1, 1, 0, 0, 0, 2)\n",
    "n_features_on = None\n",
    "feature_keywords_to_print = None  # ['max_depth', 'mean_depth', 'node_count']\n",
    "n_similar_real_games_to_print = 3\n",
    "key_features = None  # dict(section_doesnt_exist_setup=0)\n",
    "\n",
    "sample_key = model._visualize_sample_by_key(sample_key, feature_keywords_to_print=feature_keywords_to_print, postprocess_sample=True)\n",
    "sample = model.population[sample_key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(model.fitness_values.values())\n",
    "plt.hist(values, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = model.postprocessor(sample)\n",
    "game_fitness, game_features = model._score_proposal(game, return_features=True)\n",
    "{k: v for k, v in game_features.items() if 'preferences' in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_game_str = \"\"\"\n",
    "(define (game evo-2029-226-0) (:domain medium-objects-room-v1)\n",
    "(:constraints\n",
    "  (and\n",
    "    (preference preference0\n",
    "      (exists (?v0 - golfball ?v1 - doggie_bed)\n",
    "        (then\n",
    "          (once (agent_holds ?v0))\n",
    "          (hold (and (in_motion ?v0) (not (agent_holds ?v0)) ))\n",
    "          (once (in ?v1 ?v0) )\n",
    "       )\n",
    "     )\n",
    "   )\n",
    "    (preference preference1\n",
    "      (exists (?v0 - ball)\n",
    "        (then\n",
    "          (once (and (agent_holds ?v0) (adjacent bed agent)))\n",
    "          (hold (and (not (agent_holds ?v0)) (in_motion ?v0)))\n",
    "          (once (not (in_motion ?v0)))\n",
    "       )\n",
    "     )\n",
    "   )\n",
    "    (preference preference2\n",
    "      (exists (?v2 - dodgeball ?v0 - (either hexagonal_bin))\n",
    "        (then\n",
    "          (once (agent_holds ?v2))\n",
    "          (hold (and (in_motion ?v2) (not (agent_holds ?v2))))\n",
    "          (once (in ?v0 ?v2))\n",
    "       )\n",
    "     )\n",
    "   )\n",
    "    (preference preference3\n",
    "      (exists (?v1 - (either golfball_orange))\n",
    "        (then\n",
    "          (once (agent_holds ?v1))\n",
    "          (hold (and (not (agent_holds ?v1)) (in_motion ?v1)))\n",
    "          (once (not (in_motion ?v1)))\n",
    "       )\n",
    "     )\n",
    "   )\n",
    " )\n",
    ")\n",
    "(:terminal\n",
    "  (>= (count preference2) 8)\n",
    ")\n",
    "(:scoring\n",
    "  (* 4 (count preference0) (count preference3) (count preference1))\n",
    ")\n",
    ")\n",
    "\"\"\".strip()\n",
    "game = model.postprocessor(sample)\n",
    "game_fitness, game_features = model._score_proposal(game, return_features=True)\n",
    "game_features_tensor = model._features_to_tensor(game_features)\n",
    "\n",
    "edited_game = grammar_parser.parse(edited_game_str)\n",
    "edited_game_fitness, edited_game_features = model._score_proposal(edited_game, return_features=True)\n",
    "edited_game_features_tensor = model._features_to_tensor(edited_game_features)\n",
    "print(edited_game_fitness)\n",
    "\n",
    "for sample_key in game_features:\n",
    "    if edited_game_features[sample_key] != game_features[sample_key]:\n",
    "        print(sample_key, game_features[sample_key], edited_game_features[sample_key])\n",
    "\n",
    "\n",
    "\n",
    "utils.evaluate_comparison_energy_contributions(\n",
    "    game_features_tensor, edited_game_features_tensor,\n",
    "    ast_printer.ast_to_string(game, '\\n'), edited_game_str,\n",
    "    model.fitness_function, model.feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ast_printer.ast_to_string(sample, '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ast_printer.ast_to_string(model._gen_regrowth_sample(sample, model.rng), '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '(preference preference1  (exists (?v0 - (either golfball dodgeball) ?v1 - hexagonal_bin)    (at-end      (in ?v1 ?v0)   ) ))'\n",
    "s2 = '(preference preference0  (exists (?v0 - (either golfball dodgeball) ?v1 - hexagonal_bin)    (at-end      (in ?v1 ?v0)   ) ))'\n",
    "strs = [s1, s2]\n",
    "cleaned_strs = []\n",
    "\n",
    "for s in strs:\n",
    "    pref_index = s.index('(preference')\n",
    "    space_index = s.index(' ', pref_index)\n",
    "    space_after_pref_name_index = s.index(' ', space_index + 1)\n",
    "    pref_without_name = s[space_after_pref_name_index:]\n",
    "    cleaned_strs.append(pref_without_name)\n",
    "\n",
    "print(len(set(cleaned_strs)))\n",
    "print(cleaned_strs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fitness_rank_predicates\n",
    "\n",
    "def real_games_to_keys(map_elites_sampler: MAPElitesSampler, real_asts: typing.List[tatsu.ast.AST]) -> typing.List[str]:\n",
    "    return set([map_elites_sampler._features_to_key(ast, map_elites_sampler._proposal_to_features(ast)) for ast in real_asts])\n",
    "    \n",
    "\n",
    "real_game_keys = real_games_to_keys(model, game_asts)\n",
    "high_quality_sample_keys = set([k for k, v in model.fitness_values.items() if v > 70])\n",
    "high_quality_no_real_game_keys = high_quality_sample_keys - real_game_keys\n",
    "print(len(real_game_keys), len(high_quality_sample_keys), len(real_game_keys.intersection(high_quality_sample_keys)), len(high_quality_no_real_game_keys))\n",
    "\n",
    "\n",
    "high_quality_no_real_game_keys = [t[0] for t in sorted([(k, model.fitness_values[k]) for k in high_quality_sample_keys if k not in real_game_keys], key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "sample_key = high_quality_no_real_game_keys[index]\n",
    "n_features_on = None\n",
    "feature_keywords_to_print = ['max_depth', 'mean_depth', 'node_count']\n",
    "n_similar_real_games_to_print = 3 \n",
    "key_features = dict(section_doesnt_exist_setup=0)\n",
    "\n",
    "sample_key = model._visualize_sample_by_key(sample_key, feature_keywords_to_print=feature_keywords_to_print, postprocess_sample=True)\n",
    "print_nearest_real_games(model.population[sample_key], n_similar_real_games_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_set_bits(n): \n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "     \n",
    "    return count\n",
    "\n",
    "\n",
    "key_bits_to_fitness = defaultdict(list) \n",
    "\n",
    "for sample_key, fitness in current_uniform.fitness_values.items():\n",
    "    key_bits_to_fitness[count_set_bits(sample_key)].append(fitness)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for n in sorted(key_bits_to_fitness):\n",
    "    scores = key_bits_to_fitness[n]\n",
    "    rows.append((n, len(scores), np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "display(Markdown(tabulate.tabulate(rows, headers=['n', 'count', 'fitness mean', 'fitness std'], tablefmt='github')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70\n",
    "\n",
    "def count_set_bits(n):\n",
    " \n",
    "    count = 0\n",
    "    while (n):\n",
    "        n &= (n-1)\n",
    "        count+= 1\n",
    "     \n",
    "    return count\n",
    "\n",
    "\n",
    "key_bits_to_fitness = defaultdict(list) \n",
    "\n",
    "for sample_key, fitness in evo_sampler_map_elites_ucb.fitness_values.items():\n",
    "    if fitness > threshold:\n",
    "        key_bits_to_fitness[count_set_bits(sample_key)].append(fitness)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for n in sorted(key_bits_to_fitness):\n",
    "    scores = key_bits_to_fitness[n]\n",
    "    rows.append((n, len(scores), np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "display(Markdown(tabulate.tabulate(rows, headers=['n', 'count', 'fitness mean', 'fitness std'], tablefmt='github')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evolutionary_sampler_behavioral_features import build_behavioral_features_featurizer, BASIC_BINNED, BASIC_WITH_NODE_DEPTH\n",
    "\n",
    "\n",
    "featurizer = build_behavioral_features_featurizer(BASIC_WITH_NODE_DEPTH)\n",
    "_ = [featurizer.parse(current_thompson.population[current_thompson.top_sample_key(i)], 'interactive-beta.pddl', return_row=False) for i in range(1, 51)]\n",
    "d_generated = featurizer.to_df()\n",
    "d_generated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = build_behavioral_features_featurizer(BASIC_WITH_NODE_DEPTH)\n",
    "_ = [featurizer.parse(game_asts[i], 'interactive-beta.pddl', return_row=False) for i in range(len(game_asts))]\n",
    "d_real = featurizer.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "generated_values = d_generated[featurizer.headers[4:-1]].values.T.astype(float)\n",
    "real_values = d_real[featurizer.headers[4:-1]].values.T.astype(float)\n",
    "generated_values += np.random.normal(0, 0.1, size=generated_values.shape)\n",
    "real_values += np.random.normal(0, 0.1, size=real_values.shape)\n",
    "ax.scatter(*real_values, s=10)\n",
    "ax.scatter(*generated_values, s=10)\n",
    "ax.set_xlabel('Node count')\n",
    "ax.set_ylabel('# Objects')\n",
    "ax.set_zlabel('# Predicates')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_df.groupby('real')[[c for c in fitness_df.columns if 'length_of_then' in c]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../reward-machine/')\n",
    "\n",
    "import reward_machine_sample_filter\n",
    "trace_filter = reward_machine_sample_filter.TraceFinderASTParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_key, sample in models[1].population.items():\n",
    "    traces_by_key, expected_keys = trace_filter(sample)\n",
    "    if len(traces_by_key) == 0:\n",
    "        if all(key not in trace_filter.preferences_or_sections_with_implemented_predicates for key in expected_keys):\n",
    "            print(f'Key {sample_key} with fitness {models[1].fitness_values[sample_key]:.2f} has no traces because no predicates are implemented: {list(trace_filter.not_implemented_predicate_counts.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_key, sample in enumerate(game_asts):\n",
    "    traces_by_key, expected_keys = trace_filter(sample)\n",
    "    if len(traces_by_key) == 0:\n",
    "        if all(key not in trace_filter.preferences_or_sections_with_implemented_predicates for key in expected_keys):\n",
    "            print(f'Key {sample_key} with fitness {models[1].fitness_values[sample_key]:.2f} has no traces because no predicates are implemented: {list(trace_filter.not_implemented_predicate_counts.keys())}')\n",
    "        else:\n",
    "            print(f'Key {sample_key} with fitness {models[1].fitness_values[sample_key]:.2f} has no traces because no traces satisfy the implemented predicates: {list(trace_filter.not_implemented_predicate_counts.keys())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_parser.rulemap['super_predicate_and'].ast._children[1].exp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
